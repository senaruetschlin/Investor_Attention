{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytrends import dailydata\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of keywords will be here - can create a loop for this as well\n",
    "#SOURCE: https://stockanalysis.com/list/dow-jones-stocks/\n",
    "djia_tickers = [\n",
    " 'MSFT',\n",
    " 'AAPL', \n",
    " 'Visa', #Visa ticker is just V - google trends might not reflect that correctly so using Visa instead; need to redo - 100 comes before 2013\n",
    " 'JPM',\n",
    " 'UNH', #need to redo - 100 comes before 2013\n",
    " 'WMT',\n",
    " 'JNJ',\n",
    " 'PG', \n",
    " 'HD', \n",
    " 'MRK',\n",
    " 'CVX',\n",
    " 'CRM',\n",
    " 'KO',\n",
    " 'MCD', \n",
    " 'CSCO',\n",
    " 'INTC',\n",
    " 'DIS',\n",
    " 'VZ',\n",
    " 'AMGN', \n",
    " 'IBM',\n",
    " 'CAT',\n",
    " 'NKE',\n",
    " 'AXP', \n",
    " 'HON',\n",
    " 'BA',\n",
    " 'GS',\n",
    " 'MMM', \n",
    " 'TRV',\n",
    " 'TSLA',\n",
    " 'WBA'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cryptocurrency_names_with_price = [\n",
    "    'Bitcoin price', \n",
    "    'Ethereum price', \n",
    "    'Binance Coin price', \n",
    "    'Solana price', \n",
    "    'XRP price', \n",
    "    'Cardano price', \n",
    "    'Avalanche price', \n",
    "    'Dogecoin price', \n",
    "    'Chainlink price', \n",
    "    'Polkadot price', \n",
    "    'Polygon price',\n",
    "    'Terra price',\n",
    "    'Shiba Inu price', \n",
    "    'Bitcoin Cash price', \n",
    "    'Litecoin price', \n",
    "    'Immutable X price', \n",
    "    'Uniswap price', \n",
    "    'Filecoin price', \n",
    "    'Cosmos price',\n",
    "    'Hedera Hashgraph price', \n",
    "    'Ethereum Classic price', \n",
    "    'Stacks price', \n",
    "    'Opium price', \n",
    "    'Apt Coin price', \n",
    "    'NEAR Protocol price', \n",
    "    'Algorand price', \n",
    "    'Stellar price', \n",
    "    'VeChain price',\n",
    "    'Injective Protocol price',\n",
    "    'Tia Token price'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_trends(inputlist):\n",
    "\n",
    "    for string in inputlist:\n",
    "            # Define the file name with .csv extension\n",
    "        file_name = f\"{string}_trends.csv\"\n",
    "        try:\n",
    "            # Make the request to Google Trends API\n",
    "            data = dailydata.get_daily_data(string, 2013, 1, 2023, 12, geo='US').reset_index()\n",
    "            cols = ['date', f'{string}']\n",
    "            data[cols].to_csv(file_name, index=False) #we only need the two columns \n",
    "                \n",
    "            print(f\"CSV file '{file_name}' has been created.\")   \n",
    "            time.sleep(60)             \n",
    "        except Exception as e:\n",
    "            if \"429\" in str(e):\n",
    "                # Backoff strategy\n",
    "                wait_time = 300\n",
    "                print(f\"Too many requests. Retrying in {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "\n",
    "                \n",
    "            else:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                if not data.empty:\n",
    "                    data.to_csv(file_name, index=False)\n",
    "                break  # Exit the retry loop if it's not a 429 error\n",
    "\n",
    "    return f\"function is complete.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIS:2013-01-01 2013-01-31\n",
      "DIS:2013-02-01 2013-02-28\n",
      "DIS:2013-03-01 2013-03-31\n",
      "DIS:2013-04-01 2013-04-30\n",
      "DIS:2013-05-01 2013-05-31\n",
      "DIS:2013-06-01 2013-06-30\n",
      "DIS:2013-07-01 2013-07-31\n",
      "DIS:2013-08-01 2013-08-31\n",
      "DIS:2013-09-01 2013-09-30\n",
      "DIS:2013-10-01 2013-10-31\n",
      "DIS:2013-11-01 2013-11-30\n",
      "DIS:2013-12-01 2013-12-31\n",
      "DIS:2014-01-01 2014-01-31\n",
      "DIS:2014-02-01 2014-02-28\n",
      "DIS:2014-03-01 2014-03-31\n",
      "DIS:2014-04-01 2014-04-30\n",
      "DIS:2014-05-01 2014-05-31\n",
      "DIS:2014-06-01 2014-06-30\n",
      "DIS:2014-07-01 2014-07-31\n",
      "DIS:2014-08-01 2014-08-31\n",
      "DIS:2014-09-01 2014-09-30\n",
      "DIS:2014-10-01 2014-10-31\n",
      "DIS:2014-11-01 2014-11-30\n",
      "DIS:2014-12-01 2014-12-31\n",
      "DIS:2015-01-01 2015-01-31\n",
      "DIS:2015-02-01 2015-02-28\n",
      "DIS:2015-03-01 2015-03-31\n",
      "DIS:2015-04-01 2015-04-30\n",
      "DIS:2015-05-01 2015-05-31\n",
      "DIS:2015-06-01 2015-06-30\n",
      "DIS:2015-07-01 2015-07-31\n",
      "DIS:2015-08-01 2015-08-31\n",
      "DIS:2015-09-01 2015-09-30\n",
      "DIS:2015-10-01 2015-10-31\n",
      "DIS:2015-11-01 2015-11-30\n",
      "DIS:2015-12-01 2015-12-31\n",
      "DIS:2016-01-01 2016-01-31\n",
      "DIS:2016-02-01 2016-02-29\n",
      "DIS:2016-03-01 2016-03-31\n",
      "DIS:2016-04-01 2016-04-30\n",
      "DIS:2016-05-01 2016-05-31\n",
      "DIS:2016-06-01 2016-06-30\n",
      "DIS:2016-07-01 2016-07-31\n",
      "DIS:2016-08-01 2016-08-31\n",
      "DIS:2016-09-01 2016-09-30\n",
      "DIS:2016-10-01 2016-10-31\n",
      "DIS:2016-11-01 2016-11-30\n",
      "DIS:2016-12-01 2016-12-31\n",
      "DIS:2017-01-01 2017-01-31\n",
      "DIS:2017-02-01 2017-02-28\n",
      "DIS:2017-03-01 2017-03-31\n",
      "DIS:2017-04-01 2017-04-30\n",
      "DIS:2017-05-01 2017-05-31\n",
      "DIS:2017-06-01 2017-06-30\n",
      "DIS:2017-07-01 2017-07-31\n",
      "DIS:2017-08-01 2017-08-31\n",
      "DIS:2017-09-01 2017-09-30\n",
      "DIS:2017-10-01 2017-10-31\n",
      "DIS:2017-11-01 2017-11-30\n",
      "DIS:2017-12-01 2017-12-31\n",
      "DIS:2018-01-01 2018-01-31\n",
      "DIS:2018-02-01 2018-02-28\n",
      "DIS:2018-03-01 2018-03-31\n",
      "DIS:2018-04-01 2018-04-30\n",
      "DIS:2018-05-01 2018-05-31\n",
      "DIS:2018-06-01 2018-06-30\n",
      "DIS:2018-07-01 2018-07-31\n",
      "DIS:2018-08-01 2018-08-31\n",
      "DIS:2018-09-01 2018-09-30\n",
      "DIS:2018-10-01 2018-10-31\n",
      "DIS:2018-11-01 2018-11-30\n",
      "DIS:2018-12-01 2018-12-31\n",
      "DIS:2019-01-01 2019-01-31\n",
      "DIS:2019-02-01 2019-02-28\n",
      "DIS:2019-03-01 2019-03-31\n",
      "DIS:2019-04-01 2019-04-30\n",
      "DIS:2019-05-01 2019-05-31\n",
      "DIS:2019-06-01 2019-06-30\n",
      "DIS:2019-07-01 2019-07-31\n",
      "DIS:2019-08-01 2019-08-31\n",
      "DIS:2019-09-01 2019-09-30\n",
      "DIS:2019-10-01 2019-10-31\n",
      "DIS:2019-11-01 2019-11-30\n",
      "DIS:2019-12-01 2019-12-31\n",
      "DIS:2020-01-01 2020-01-31\n",
      "DIS:2020-02-01 2020-02-29\n",
      "DIS:2020-03-01 2020-03-31\n",
      "DIS:2020-04-01 2020-04-30\n",
      "DIS:2020-05-01 2020-05-31\n",
      "DIS:2020-06-01 2020-06-30\n",
      "DIS:2020-07-01 2020-07-31\n",
      "DIS:2020-08-01 2020-08-31\n",
      "DIS:2020-09-01 2020-09-30\n",
      "DIS:2020-10-01 2020-10-31\n",
      "DIS:2020-11-01 2020-11-30\n",
      "DIS:2020-12-01 2020-12-31\n",
      "DIS:2021-01-01 2021-01-31\n",
      "DIS:2021-02-01 2021-02-28\n",
      "DIS:2021-03-01 2021-03-31\n",
      "DIS:2021-04-01 2021-04-30\n",
      "DIS:2021-05-01 2021-05-31\n",
      "DIS:2021-06-01 2021-06-30\n",
      "DIS:2021-07-01 2021-07-31\n",
      "DIS:2021-08-01 2021-08-31\n",
      "DIS:2021-09-01 2021-09-30\n",
      "DIS:2021-10-01 2021-10-31\n",
      "DIS:2021-11-01 2021-11-30\n",
      "DIS:2021-12-01 2021-12-31\n",
      "DIS:2022-01-01 2022-01-31\n",
      "DIS:2022-02-01 2022-02-28\n",
      "DIS:2022-03-01 2022-03-31\n",
      "DIS:2022-04-01 2022-04-30\n",
      "DIS:2022-05-01 2022-05-31\n",
      "DIS:2022-06-01 2022-06-30\n",
      "DIS:2022-07-01 2022-07-31\n",
      "DIS:2022-08-01 2022-08-31\n",
      "DIS:2022-09-01 2022-09-30\n",
      "DIS:2022-10-01 2022-10-31\n",
      "DIS:2022-11-01 2022-11-30\n",
      "DIS:2022-12-01 2022-12-31\n",
      "DIS:2023-01-01 2023-01-31\n",
      "DIS:2023-02-01 2023-02-28\n",
      "DIS:2023-03-01 2023-03-31\n",
      "DIS:2023-04-01 2023-04-30\n",
      "DIS:2023-05-01 2023-05-31\n",
      "DIS:2023-06-01 2023-06-30\n",
      "DIS:2023-07-01 2023-07-31\n",
      "DIS:2023-08-01 2023-08-31\n",
      "DIS:2023-09-01 2023-09-30\n",
      "DIS:2023-10-01 2023-10-31\n",
      "DIS:2023-11-01 2023-11-30\n",
      "DIS:2023-12-01 2023-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pytrends/dailydata.py:123: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  complete[f'{word}_monthly'].ffill(inplace=True)  # fill NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'DIS.csv' has been created.\n",
      "VZ:2013-01-01 2013-01-31\n",
      "VZ:2013-02-01 2013-02-28\n",
      "VZ:2013-03-01 2013-03-31\n",
      "VZ:2013-04-01 2013-04-30\n",
      "VZ:2013-05-01 2013-05-31\n",
      "VZ:2013-06-01 2013-06-30\n",
      "VZ:2013-07-01 2013-07-31\n",
      "VZ:2013-08-01 2013-08-31\n",
      "VZ:2013-09-01 2013-09-30\n",
      "VZ:2013-10-01 2013-10-31\n",
      "VZ:2013-11-01 2013-11-30\n",
      "VZ:2013-12-01 2013-12-31\n",
      "VZ:2014-01-01 2014-01-31\n",
      "VZ:2014-02-01 2014-02-28\n",
      "VZ:2014-03-01 2014-03-31\n",
      "VZ:2014-04-01 2014-04-30\n",
      "VZ:2014-05-01 2014-05-31\n",
      "VZ:2014-06-01 2014-06-30\n",
      "VZ:2014-07-01 2014-07-31\n",
      "VZ:2014-08-01 2014-08-31\n",
      "VZ:2014-09-01 2014-09-30\n",
      "VZ:2014-10-01 2014-10-31\n",
      "VZ:2014-11-01 2014-11-30\n",
      "VZ:2014-12-01 2014-12-31\n",
      "VZ:2015-01-01 2015-01-31\n",
      "VZ:2015-02-01 2015-02-28\n",
      "VZ:2015-03-01 2015-03-31\n",
      "VZ:2015-04-01 2015-04-30\n",
      "VZ:2015-05-01 2015-05-31\n",
      "VZ:2015-06-01 2015-06-30\n",
      "VZ:2015-07-01 2015-07-31\n",
      "VZ:2015-08-01 2015-08-31\n",
      "VZ:2015-09-01 2015-09-30\n",
      "VZ:2015-10-01 2015-10-31\n",
      "VZ:2015-11-01 2015-11-30\n",
      "VZ:2015-12-01 2015-12-31\n",
      "VZ:2016-01-01 2016-01-31\n",
      "VZ:2016-02-01 2016-02-29\n",
      "VZ:2016-03-01 2016-03-31\n",
      "VZ:2016-04-01 2016-04-30\n",
      "VZ:2016-05-01 2016-05-31\n",
      "VZ:2016-06-01 2016-06-30\n",
      "VZ:2016-07-01 2016-07-31\n",
      "VZ:2016-08-01 2016-08-31\n",
      "VZ:2016-09-01 2016-09-30\n",
      "VZ:2016-10-01 2016-10-31\n",
      "VZ:2016-11-01 2016-11-30\n",
      "VZ:2016-12-01 2016-12-31\n",
      "VZ:2017-01-01 2017-01-31\n",
      "VZ:2017-02-01 2017-02-28\n",
      "VZ:2017-03-01 2017-03-31\n",
      "VZ:2017-04-01 2017-04-30\n",
      "VZ:2017-05-01 2017-05-31\n",
      "VZ:2017-06-01 2017-06-30\n",
      "VZ:2017-07-01 2017-07-31\n",
      "VZ:2017-08-01 2017-08-31\n",
      "VZ:2017-09-01 2017-09-30\n",
      "VZ:2017-10-01 2017-10-31\n",
      "VZ:2017-11-01 2017-11-30\n",
      "VZ:2017-12-01 2017-12-31\n",
      "VZ:2018-01-01 2018-01-31\n",
      "VZ:2018-02-01 2018-02-28\n",
      "VZ:2018-03-01 2018-03-31\n",
      "VZ:2018-04-01 2018-04-30\n",
      "VZ:2018-05-01 2018-05-31\n",
      "VZ:2018-06-01 2018-06-30\n",
      "VZ:2018-07-01 2018-07-31\n",
      "VZ:2018-08-01 2018-08-31\n",
      "VZ:2018-09-01 2018-09-30\n",
      "VZ:2018-10-01 2018-10-31\n",
      "VZ:2018-11-01 2018-11-30\n",
      "VZ:2018-12-01 2018-12-31\n",
      "VZ:2019-01-01 2019-01-31\n",
      "VZ:2019-02-01 2019-02-28\n",
      "VZ:2019-03-01 2019-03-31\n",
      "VZ:2019-04-01 2019-04-30\n",
      "VZ:2019-05-01 2019-05-31\n",
      "VZ:2019-06-01 2019-06-30\n",
      "VZ:2019-07-01 2019-07-31\n",
      "VZ:2019-08-01 2019-08-31\n",
      "VZ:2019-09-01 2019-09-30\n",
      "VZ:2019-10-01 2019-10-31\n",
      "VZ:2019-11-01 2019-11-30\n",
      "VZ:2019-12-01 2019-12-31\n",
      "VZ:2020-01-01 2020-01-31\n",
      "VZ:2020-02-01 2020-02-29\n",
      "VZ:2020-03-01 2020-03-31\n",
      "VZ:2020-04-01 2020-04-30\n",
      "VZ:2020-05-01 2020-05-31\n",
      "VZ:2020-06-01 2020-06-30\n",
      "VZ:2020-07-01 2020-07-31\n",
      "VZ:2020-08-01 2020-08-31\n",
      "VZ:2020-09-01 2020-09-30\n",
      "VZ:2020-10-01 2020-10-31\n",
      "VZ:2020-11-01 2020-11-30\n",
      "VZ:2020-12-01 2020-12-31\n",
      "VZ:2021-01-01 2021-01-31\n",
      "VZ:2021-02-01 2021-02-28\n",
      "VZ:2021-03-01 2021-03-31\n",
      "VZ:2021-04-01 2021-04-30\n",
      "VZ:2021-05-01 2021-05-31\n",
      "VZ:2021-06-01 2021-06-30\n",
      "VZ:2021-07-01 2021-07-31\n",
      "VZ:2021-08-01 2021-08-31\n",
      "VZ:2021-09-01 2021-09-30\n",
      "VZ:2021-10-01 2021-10-31\n",
      "VZ:2021-11-01 2021-11-30\n",
      "VZ:2021-12-01 2021-12-31\n",
      "VZ:2022-01-01 2022-01-31\n",
      "VZ:2022-02-01 2022-02-28\n",
      "VZ:2022-03-01 2022-03-31\n",
      "VZ:2022-04-01 2022-04-30\n",
      "VZ:2022-05-01 2022-05-31\n",
      "VZ:2022-06-01 2022-06-30\n",
      "VZ:2022-07-01 2022-07-31\n",
      "VZ:2022-08-01 2022-08-31\n",
      "VZ:2022-09-01 2022-09-30\n",
      "VZ:2022-10-01 2022-10-31\n",
      "VZ:2022-11-01 2022-11-30\n",
      "VZ:2022-12-01 2022-12-31\n",
      "VZ:2023-01-01 2023-01-31\n",
      "VZ:2023-02-01 2023-02-28\n",
      "VZ:2023-03-01 2023-03-31\n",
      "VZ:2023-04-01 2023-04-30\n",
      "VZ:2023-05-01 2023-05-31\n",
      "VZ:2023-06-01 2023-06-30\n",
      "VZ:2023-07-01 2023-07-31\n",
      "VZ:2023-08-01 2023-08-31\n",
      "VZ:2023-09-01 2023-09-30\n",
      "VZ:2023-10-01 2023-10-31\n",
      "VZ:2023-11-01 2023-11-30\n",
      "VZ:2023-12-01 2023-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pytrends/dailydata.py:123: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  complete[f'{word}_monthly'].ffill(inplace=True)  # fill NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'VZ.csv' has been created.\n",
      "AMGN:2013-01-01 2013-01-31\n",
      "AMGN:2013-02-01 2013-02-28\n",
      "AMGN:2013-03-01 2013-03-31\n",
      "AMGN:2013-04-01 2013-04-30\n",
      "AMGN:2013-05-01 2013-05-31\n",
      "AMGN:2013-06-01 2013-06-30\n",
      "AMGN:2013-07-01 2013-07-31\n",
      "AMGN:2013-08-01 2013-08-31\n",
      "AMGN:2013-09-01 2013-09-30\n",
      "AMGN:2013-10-01 2013-10-31\n",
      "AMGN:2013-11-01 2013-11-30\n",
      "AMGN:2013-12-01 2013-12-31\n",
      "AMGN:2014-01-01 2014-01-31\n",
      "AMGN:2014-02-01 2014-02-28\n",
      "AMGN:2014-03-01 2014-03-31\n",
      "AMGN:2014-04-01 2014-04-30\n",
      "AMGN:2014-05-01 2014-05-31\n",
      "AMGN:2014-06-01 2014-06-30\n",
      "AMGN:2014-07-01 2014-07-31\n",
      "AMGN:2014-08-01 2014-08-31\n",
      "AMGN:2014-09-01 2014-09-30\n",
      "AMGN:2014-10-01 2014-10-31\n",
      "AMGN:2014-11-01 2014-11-30\n",
      "AMGN:2014-12-01 2014-12-31\n",
      "AMGN:2015-01-01 2015-01-31\n",
      "AMGN:2015-02-01 2015-02-28\n",
      "AMGN:2015-03-01 2015-03-31\n",
      "AMGN:2015-04-01 2015-04-30\n",
      "AMGN:2015-05-01 2015-05-31\n",
      "AMGN:2015-06-01 2015-06-30\n",
      "AMGN:2015-07-01 2015-07-31\n",
      "AMGN:2015-08-01 2015-08-31\n",
      "AMGN:2015-09-01 2015-09-30\n",
      "AMGN:2015-10-01 2015-10-31\n",
      "AMGN:2015-11-01 2015-11-30\n",
      "AMGN:2015-12-01 2015-12-31\n",
      "AMGN:2016-01-01 2016-01-31\n",
      "AMGN:2016-02-01 2016-02-29\n",
      "AMGN:2016-03-01 2016-03-31\n",
      "AMGN:2016-04-01 2016-04-30\n",
      "AMGN:2016-05-01 2016-05-31\n",
      "AMGN:2016-06-01 2016-06-30\n",
      "AMGN:2016-07-01 2016-07-31\n",
      "AMGN:2016-08-01 2016-08-31\n",
      "AMGN:2016-09-01 2016-09-30\n",
      "AMGN:2016-10-01 2016-10-31\n",
      "AMGN:2016-11-01 2016-11-30\n",
      "AMGN:2016-12-01 2016-12-31\n",
      "AMGN:2017-01-01 2017-01-31\n",
      "AMGN:2017-02-01 2017-02-28\n",
      "AMGN:2017-03-01 2017-03-31\n",
      "AMGN:2017-04-01 2017-04-30\n",
      "AMGN:2017-05-01 2017-05-31\n",
      "AMGN:2017-06-01 2017-06-30\n",
      "AMGN:2017-07-01 2017-07-31\n",
      "AMGN:2017-08-01 2017-08-31\n",
      "AMGN:2017-09-01 2017-09-30\n",
      "AMGN:2017-10-01 2017-10-31\n",
      "AMGN:2017-11-01 2017-11-30\n",
      "AMGN:2017-12-01 2017-12-31\n",
      "AMGN:2018-01-01 2018-01-31\n",
      "AMGN:2018-02-01 2018-02-28\n",
      "AMGN:2018-03-01 2018-03-31\n",
      "AMGN:2018-04-01 2018-04-30\n",
      "AMGN:2018-05-01 2018-05-31\n",
      "AMGN:2018-06-01 2018-06-30\n",
      "AMGN:2018-07-01 2018-07-31\n",
      "AMGN:2018-08-01 2018-08-31\n",
      "AMGN:2018-09-01 2018-09-30\n",
      "AMGN:2018-10-01 2018-10-31\n",
      "AMGN:2018-11-01 2018-11-30\n",
      "AMGN:2018-12-01 2018-12-31\n",
      "AMGN:2019-01-01 2019-01-31\n",
      "AMGN:2019-02-01 2019-02-28\n",
      "AMGN:2019-03-01 2019-03-31\n",
      "AMGN:2019-04-01 2019-04-30\n",
      "AMGN:2019-05-01 2019-05-31\n",
      "AMGN:2019-06-01 2019-06-30\n",
      "AMGN:2019-07-01 2019-07-31\n",
      "AMGN:2019-08-01 2019-08-31\n",
      "AMGN:2019-09-01 2019-09-30\n",
      "AMGN:2019-10-01 2019-10-31\n",
      "AMGN:2019-11-01 2019-11-30\n",
      "AMGN:2019-12-01 2019-12-31\n",
      "AMGN:2020-01-01 2020-01-31\n",
      "AMGN:2020-02-01 2020-02-29\n",
      "AMGN:2020-03-01 2020-03-31\n",
      "AMGN:2020-04-01 2020-04-30\n",
      "AMGN:2020-05-01 2020-05-31\n",
      "AMGN:2020-06-01 2020-06-30\n",
      "AMGN:2020-07-01 2020-07-31\n",
      "AMGN:2020-08-01 2020-08-31\n",
      "AMGN:2020-09-01 2020-09-30\n",
      "AMGN:2020-10-01 2020-10-31\n",
      "AMGN:2020-11-01 2020-11-30\n",
      "AMGN:2020-12-01 2020-12-31\n",
      "AMGN:2021-01-01 2021-01-31\n",
      "AMGN:2021-02-01 2021-02-28\n",
      "AMGN:2021-03-01 2021-03-31\n",
      "AMGN:2021-04-01 2021-04-30\n",
      "AMGN:2021-05-01 2021-05-31\n",
      "AMGN:2021-06-01 2021-06-30\n",
      "AMGN:2021-07-01 2021-07-31\n",
      "AMGN:2021-08-01 2021-08-31\n",
      "AMGN:2021-09-01 2021-09-30\n",
      "AMGN:2021-10-01 2021-10-31\n",
      "AMGN:2021-11-01 2021-11-30\n",
      "AMGN:2021-12-01 2021-12-31\n",
      "AMGN:2022-01-01 2022-01-31\n",
      "AMGN:2022-02-01 2022-02-28\n",
      "AMGN:2022-03-01 2022-03-31\n",
      "AMGN:2022-04-01 2022-04-30\n",
      "AMGN:2022-05-01 2022-05-31\n",
      "AMGN:2022-06-01 2022-06-30\n",
      "AMGN:2022-07-01 2022-07-31\n",
      "AMGN:2022-08-01 2022-08-31\n",
      "AMGN:2022-09-01 2022-09-30\n",
      "AMGN:2022-10-01 2022-10-31\n",
      "AMGN:2022-11-01 2022-11-30\n",
      "AMGN:2022-12-01 2022-12-31\n",
      "AMGN:2023-01-01 2023-01-31\n",
      "AMGN:2023-02-01 2023-02-28\n",
      "AMGN:2023-03-01 2023-03-31\n",
      "AMGN:2023-04-01 2023-04-30\n",
      "AMGN:2023-05-01 2023-05-31\n",
      "AMGN:2023-06-01 2023-06-30\n",
      "AMGN:2023-07-01 2023-07-31\n",
      "AMGN:2023-08-01 2023-08-31\n",
      "AMGN:2023-09-01 2023-09-30\n",
      "AMGN:2023-10-01 2023-10-31\n",
      "AMGN:2023-11-01 2023-11-30\n",
      "AMGN:2023-12-01 2023-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pytrends/dailydata.py:123: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  complete[f'{word}_monthly'].ffill(inplace=True)  # fill NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'AMGN.csv' has been created.\n",
      "IBM:2013-01-01 2013-01-31\n",
      "IBM:2013-02-01 2013-02-28\n",
      "IBM:2013-03-01 2013-03-31\n",
      "IBM:2013-04-01 2013-04-30\n",
      "IBM:2013-05-01 2013-05-31\n",
      "IBM:2013-06-01 2013-06-30\n",
      "IBM:2013-07-01 2013-07-31\n",
      "IBM:2013-08-01 2013-08-31\n",
      "IBM:2013-09-01 2013-09-30\n",
      "IBM:2013-10-01 2013-10-31\n",
      "IBM:2013-11-01 2013-11-30\n",
      "IBM:2013-12-01 2013-12-31\n",
      "IBM:2014-01-01 2014-01-31\n",
      "IBM:2014-02-01 2014-02-28\n",
      "IBM:2014-03-01 2014-03-31\n",
      "IBM:2014-04-01 2014-04-30\n",
      "IBM:2014-05-01 2014-05-31\n",
      "IBM:2014-06-01 2014-06-30\n",
      "IBM:2014-07-01 2014-07-31\n",
      "IBM:2014-08-01 2014-08-31\n",
      "IBM:2014-09-01 2014-09-30\n",
      "IBM:2014-10-01 2014-10-31\n",
      "IBM:2014-11-01 2014-11-30\n",
      "IBM:2014-12-01 2014-12-31\n",
      "IBM:2015-01-01 2015-01-31\n",
      "IBM:2015-02-01 2015-02-28\n",
      "IBM:2015-03-01 2015-03-31\n",
      "IBM:2015-04-01 2015-04-30\n",
      "IBM:2015-05-01 2015-05-31\n",
      "IBM:2015-06-01 2015-06-30\n",
      "IBM:2015-07-01 2015-07-31\n",
      "IBM:2015-08-01 2015-08-31\n",
      "IBM:2015-09-01 2015-09-30\n",
      "IBM:2015-10-01 2015-10-31\n",
      "IBM:2015-11-01 2015-11-30\n",
      "IBM:2015-12-01 2015-12-31\n",
      "IBM:2016-01-01 2016-01-31\n",
      "IBM:2016-02-01 2016-02-29\n",
      "IBM:2016-03-01 2016-03-31\n",
      "IBM:2016-04-01 2016-04-30\n",
      "IBM:2016-05-01 2016-05-31\n",
      "IBM:2016-06-01 2016-06-30\n",
      "IBM:2016-07-01 2016-07-31\n",
      "IBM:2016-08-01 2016-08-31\n",
      "IBM:2016-09-01 2016-09-30\n",
      "IBM:2016-10-01 2016-10-31\n",
      "IBM:2016-11-01 2016-11-30\n",
      "IBM:2016-12-01 2016-12-31\n",
      "IBM:2017-01-01 2017-01-31\n",
      "IBM:2017-02-01 2017-02-28\n",
      "IBM:2017-03-01 2017-03-31\n",
      "IBM:2017-04-01 2017-04-30\n",
      "IBM:2017-05-01 2017-05-31\n",
      "IBM:2017-06-01 2017-06-30\n",
      "IBM:2017-07-01 2017-07-31\n",
      "IBM:2017-08-01 2017-08-31\n",
      "IBM:2017-09-01 2017-09-30\n",
      "IBM:2017-10-01 2017-10-31\n",
      "IBM:2017-11-01 2017-11-30\n",
      "IBM:2017-12-01 2017-12-31\n",
      "IBM:2018-01-01 2018-01-31\n",
      "IBM:2018-02-01 2018-02-28\n",
      "IBM:2018-03-01 2018-03-31\n",
      "IBM:2018-04-01 2018-04-30\n",
      "IBM:2018-05-01 2018-05-31\n",
      "IBM:2018-06-01 2018-06-30\n",
      "IBM:2018-07-01 2018-07-31\n",
      "IBM:2018-08-01 2018-08-31\n",
      "IBM:2018-09-01 2018-09-30\n",
      "IBM:2018-10-01 2018-10-31\n",
      "IBM:2018-11-01 2018-11-30\n",
      "IBM:2018-12-01 2018-12-31\n",
      "IBM:2019-01-01 2019-01-31\n",
      "IBM:2019-02-01 2019-02-28\n",
      "IBM:2019-03-01 2019-03-31\n",
      "IBM:2019-04-01 2019-04-30\n",
      "IBM:2019-05-01 2019-05-31\n",
      "IBM:2019-06-01 2019-06-30\n",
      "IBM:2019-07-01 2019-07-31\n",
      "IBM:2019-08-01 2019-08-31\n",
      "IBM:2019-09-01 2019-09-30\n",
      "IBM:2019-10-01 2019-10-31\n",
      "IBM:2019-11-01 2019-11-30\n",
      "IBM:2019-12-01 2019-12-31\n",
      "IBM:2020-01-01 2020-01-31\n",
      "IBM:2020-02-01 2020-02-29\n",
      "IBM:2020-03-01 2020-03-31\n",
      "IBM:2020-04-01 2020-04-30\n",
      "IBM:2020-05-01 2020-05-31\n",
      "IBM:2020-06-01 2020-06-30\n",
      "IBM:2020-07-01 2020-07-31\n",
      "IBM:2020-08-01 2020-08-31\n",
      "IBM:2020-09-01 2020-09-30\n",
      "IBM:2020-10-01 2020-10-31\n",
      "IBM:2020-11-01 2020-11-30\n",
      "IBM:2020-12-01 2020-12-31\n",
      "IBM:2021-01-01 2021-01-31\n",
      "IBM:2021-02-01 2021-02-28\n",
      "IBM:2021-03-01 2021-03-31\n",
      "IBM:2021-04-01 2021-04-30\n",
      "IBM:2021-05-01 2021-05-31\n",
      "IBM:2021-06-01 2021-06-30\n",
      "IBM:2021-07-01 2021-07-31\n",
      "IBM:2021-08-01 2021-08-31\n",
      "IBM:2021-09-01 2021-09-30\n",
      "IBM:2021-10-01 2021-10-31\n",
      "IBM:2021-11-01 2021-11-30\n",
      "IBM:2021-12-01 2021-12-31\n",
      "IBM:2022-01-01 2022-01-31\n",
      "IBM:2022-02-01 2022-02-28\n",
      "IBM:2022-03-01 2022-03-31\n",
      "IBM:2022-04-01 2022-04-30\n",
      "IBM:2022-05-01 2022-05-31\n",
      "IBM:2022-06-01 2022-06-30\n",
      "IBM:2022-07-01 2022-07-31\n",
      "IBM:2022-08-01 2022-08-31\n",
      "IBM:2022-09-01 2022-09-30\n",
      "IBM:2022-10-01 2022-10-31\n",
      "IBM:2022-11-01 2022-11-30\n",
      "IBM:2022-12-01 2022-12-31\n",
      "IBM:2023-01-01 2023-01-31\n",
      "IBM:2023-02-01 2023-02-28\n",
      "IBM:2023-03-01 2023-03-31\n",
      "IBM:2023-04-01 2023-04-30\n",
      "IBM:2023-05-01 2023-05-31\n",
      "IBM:2023-06-01 2023-06-30\n",
      "IBM:2023-07-01 2023-07-31\n",
      "IBM:2023-08-01 2023-08-31\n",
      "IBM:2023-09-01 2023-09-30\n",
      "IBM:2023-10-01 2023-10-31\n",
      "IBM:2023-11-01 2023-11-30\n",
      "IBM:2023-12-01 2023-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pytrends/dailydata.py:123: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  complete[f'{word}_monthly'].ffill(inplace=True)  # fill NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'IBM.csv' has been created.\n",
      "TRV:2013-01-01 2013-01-31\n",
      "TRV:2013-02-01 2013-02-28\n",
      "TRV:2013-03-01 2013-03-31\n",
      "TRV:2013-04-01 2013-04-30\n",
      "TRV:2013-05-01 2013-05-31\n",
      "TRV:2013-06-01 2013-06-30\n",
      "TRV:2013-07-01 2013-07-31\n",
      "TRV:2013-08-01 2013-08-31\n",
      "TRV:2013-09-01 2013-09-30\n",
      "TRV:2013-10-01 2013-10-31\n",
      "TRV:2013-11-01 2013-11-30\n",
      "TRV:2013-12-01 2013-12-31\n",
      "TRV:2014-01-01 2014-01-31\n",
      "TRV:2014-02-01 2014-02-28\n",
      "TRV:2014-03-01 2014-03-31\n",
      "TRV:2014-04-01 2014-04-30\n",
      "TRV:2014-05-01 2014-05-31\n",
      "TRV:2014-06-01 2014-06-30\n",
      "TRV:2014-07-01 2014-07-31\n",
      "TRV:2014-08-01 2014-08-31\n",
      "TRV:2014-09-01 2014-09-30\n",
      "TRV:2014-10-01 2014-10-31\n",
      "TRV:2014-11-01 2014-11-30\n",
      "TRV:2014-12-01 2014-12-31\n",
      "TRV:2015-01-01 2015-01-31\n",
      "TRV:2015-02-01 2015-02-28\n",
      "TRV:2015-03-01 2015-03-31\n",
      "TRV:2015-04-01 2015-04-30\n",
      "TRV:2015-05-01 2015-05-31\n",
      "TRV:2015-06-01 2015-06-30\n",
      "TRV:2015-07-01 2015-07-31\n",
      "TRV:2015-08-01 2015-08-31\n",
      "TRV:2015-09-01 2015-09-30\n",
      "TRV:2015-10-01 2015-10-31\n",
      "TRV:2015-11-01 2015-11-30\n",
      "TRV:2015-12-01 2015-12-31\n",
      "TRV:2016-01-01 2016-01-31\n",
      "TRV:2016-02-01 2016-02-29\n",
      "TRV:2016-03-01 2016-03-31\n",
      "TRV:2016-04-01 2016-04-30\n",
      "TRV:2016-05-01 2016-05-31\n",
      "TRV:2016-06-01 2016-06-30\n",
      "TRV:2016-07-01 2016-07-31\n",
      "TRV:2016-08-01 2016-08-31\n",
      "TRV:2016-09-01 2016-09-30\n",
      "TRV:2016-10-01 2016-10-31\n",
      "TRV:2016-11-01 2016-11-30\n",
      "TRV:2016-12-01 2016-12-31\n",
      "TRV:2017-01-01 2017-01-31\n",
      "TRV:2017-02-01 2017-02-28\n",
      "TRV:2017-03-01 2017-03-31\n",
      "TRV:2017-04-01 2017-04-30\n",
      "TRV:2017-05-01 2017-05-31\n",
      "TRV:2017-06-01 2017-06-30\n",
      "TRV:2017-07-01 2017-07-31\n",
      "TRV:2017-08-01 2017-08-31\n",
      "TRV:2017-09-01 2017-09-30\n",
      "TRV:2017-10-01 2017-10-31\n",
      "TRV:2017-11-01 2017-11-30\n",
      "TRV:2017-12-01 2017-12-31\n",
      "TRV:2018-01-01 2018-01-31\n",
      "TRV:2018-02-01 2018-02-28\n",
      "TRV:2018-03-01 2018-03-31\n",
      "TRV:2018-04-01 2018-04-30\n",
      "TRV:2018-05-01 2018-05-31\n",
      "TRV:2018-06-01 2018-06-30\n",
      "TRV:2018-07-01 2018-07-31\n",
      "TRV:2018-08-01 2018-08-31\n",
      "TRV:2018-09-01 2018-09-30\n",
      "TRV:2018-10-01 2018-10-31\n",
      "TRV:2018-11-01 2018-11-30\n",
      "TRV:2018-12-01 2018-12-31\n",
      "TRV:2019-01-01 2019-01-31\n",
      "TRV:2019-02-01 2019-02-28\n",
      "TRV:2019-03-01 2019-03-31\n",
      "TRV:2019-04-01 2019-04-30\n",
      "TRV:2019-05-01 2019-05-31\n",
      "TRV:2019-06-01 2019-06-30\n",
      "TRV:2019-07-01 2019-07-31\n",
      "TRV:2019-08-01 2019-08-31\n",
      "TRV:2019-09-01 2019-09-30\n",
      "TRV:2019-10-01 2019-10-31\n",
      "TRV:2019-11-01 2019-11-30\n",
      "TRV:2019-12-01 2019-12-31\n",
      "TRV:2020-01-01 2020-01-31\n",
      "TRV:2020-02-01 2020-02-29\n",
      "TRV:2020-03-01 2020-03-31\n",
      "TRV:2020-04-01 2020-04-30\n",
      "TRV:2020-05-01 2020-05-31\n",
      "TRV:2020-06-01 2020-06-30\n",
      "TRV:2020-07-01 2020-07-31\n",
      "TRV:2020-08-01 2020-08-31\n",
      "TRV:2020-09-01 2020-09-30\n",
      "TRV:2020-10-01 2020-10-31\n",
      "TRV:2020-11-01 2020-11-30\n",
      "TRV:2020-12-01 2020-12-31\n",
      "TRV:2021-01-01 2021-01-31\n",
      "TRV:2021-02-01 2021-02-28\n",
      "TRV:2021-03-01 2021-03-31\n",
      "TRV:2021-04-01 2021-04-30\n",
      "TRV:2021-05-01 2021-05-31\n",
      "TRV:2021-06-01 2021-06-30\n",
      "TRV:2021-07-01 2021-07-31\n",
      "TRV:2021-08-01 2021-08-31\n",
      "TRV:2021-09-01 2021-09-30\n",
      "TRV:2021-10-01 2021-10-31\n",
      "TRV:2021-11-01 2021-11-30\n",
      "TRV:2021-12-01 2021-12-31\n",
      "TRV:2022-01-01 2022-01-31\n",
      "TRV:2022-02-01 2022-02-28\n",
      "TRV:2022-03-01 2022-03-31\n",
      "TRV:2022-04-01 2022-04-30\n",
      "TRV:2022-05-01 2022-05-31\n",
      "TRV:2022-06-01 2022-06-30\n",
      "TRV:2022-07-01 2022-07-31\n",
      "TRV:2022-08-01 2022-08-31\n",
      "TRV:2022-09-01 2022-09-30\n",
      "TRV:2022-10-01 2022-10-31\n",
      "TRV:2022-11-01 2022-11-30\n",
      "TRV:2022-12-01 2022-12-31\n",
      "TRV:2023-01-01 2023-01-31\n",
      "TRV:2023-02-01 2023-02-28\n",
      "TRV:2023-03-01 2023-03-31\n",
      "TRV:2023-04-01 2023-04-30\n",
      "TRV:2023-05-01 2023-05-31\n",
      "TRV:2023-06-01 2023-06-30\n",
      "TRV:2023-07-01 2023-07-31\n",
      "TRV:2023-08-01 2023-08-31\n",
      "TRV:2023-09-01 2023-09-30\n",
      "TRV:2023-10-01 2023-10-31\n",
      "TRV:2023-11-01 2023-11-30\n",
      "TRV:2023-12-01 2023-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pytrends/dailydata.py:123: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  complete[f'{word}_monthly'].ffill(inplace=True)  # fill NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'TRV.csv' has been created.\n",
      "TSLA:2013-01-01 2013-01-31\n",
      "TSLA:2013-02-01 2013-02-28\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgoogle_trends\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdjia_tickers\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[61], line 8\u001b[0m, in \u001b[0;36mgoogle_trends\u001b[0;34m(inputlist)\u001b[0m\n\u001b[1;32m      5\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstring\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Make the request to Google Trends API\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mdailydata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_daily_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2013\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2023\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      9\u001b[0m     cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstring\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m     data[cols]\u001b[38;5;241m.\u001b[39mto_csv(file_name, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m#we only need the two columns \u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pytrends/dailydata.py:117\u001b[0m, in \u001b[0;36mget_daily_data\u001b[0;34m(word, start_year, start_mon, stop_year, stop_mon, geo, verbose, wait_time)\u001b[0m\n\u001b[1;32m    115\u001b[0m     results[current] \u001b[38;5;241m=\u001b[39m _fetch_data(pytrends, build_payload, timeframe)\n\u001b[1;32m    116\u001b[0m     current \u001b[38;5;241m=\u001b[39m last_date_of_month \u001b[38;5;241m+\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m     sleep(wait_time)  \u001b[38;5;66;03m# don't go too fast or Google will send 429s\u001b[39;00m\n\u001b[1;32m    119\u001b[0m daily \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(results\u001b[38;5;241m.\u001b[39mvalues())\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124misPartial\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    120\u001b[0m complete \u001b[38;5;241m=\u001b[39m daily\u001b[38;5;241m.\u001b[39mjoin(monthly, lsuffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_unscaled\u001b[39m\u001b[38;5;124m'\u001b[39m, rsuffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_monthly\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "google_trends(djia_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_trends(cryptocurrency_names_with_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_list = [   #   'Polkadot price', \n",
    "  #  'Polygon price',\n",
    "   # 'Terra price',\n",
    "    #    'Stellar price',\n",
    "\n",
    "    'Tia Token price'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too many requests. Retrying in 300 seconds...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTooManyRequestsError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 8\u001b[0m, in \u001b[0;36mgoogle_trends\u001b[0;34m(inputlist)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Make the request to Google Trends API\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mdailydata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_daily_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2013\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2023\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      9\u001b[0m     cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstring\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pytrends/dailydata.py:103\u001b[0m, in \u001b[0;36mget_daily_data\u001b[0;34m(word, start_year, start_mon, stop_year, stop_mon, geo, verbose, wait_time)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Obtain monthly data for all months in years [start_year, stop_year]\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m monthly \u001b[38;5;241m=\u001b[39m \u001b[43m_fetch_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpytrends\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuild_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mconvert_dates_to_timeframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_date\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Get daily data, month by month\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pytrends/dailydata.py:45\u001b[0m, in \u001b[0;36m_fetch_data\u001b[0;34m(pytrends, build_payload, timeframe)\u001b[0m\n\u001b[1;32m     44\u001b[0m         fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpytrends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterest_over_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pytrends/request.py:232\u001b[0m, in \u001b[0;36mTrendReq.interest_over_time\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# make the request and parse the returned json\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m req_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTEREST_OVER_TIME_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_METHOD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrim_chars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mover_time_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(req_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimelineData\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pytrends/request.py:159\u001b[0m, in \u001b[0;36mTrendReq._get_data\u001b[0;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m status_codes\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mtoo_many_requests:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTooManyRequestsError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mResponseError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
      "\u001b[0;31mTooManyRequestsError\u001b[0m: The request failed: Google returned a response with code 429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgoogle_trends\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdated_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 19\u001b[0m, in \u001b[0;36mgoogle_trends\u001b[0;34m(inputlist)\u001b[0m\n\u001b[1;32m     17\u001b[0m     wait_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many requests. Retrying in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwait_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "google_trends(updated_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv_files(csv_files, file_name):\n",
    "    dfs = []\n",
    "    folder_name = 'google_trends'\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(folder_name, file)\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Error: File '{file_path}' does not exist.\")\n",
    "            return None\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        dfs.append(df)\n",
    "\n",
    "    merged_df = dfs[0]\n",
    "    for df in dfs[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on='date')\n",
    "\n",
    "    melted_df = merged_df.melt(id_vars=['date'], var_name='stock_name', value_name='attention_ticker')\n",
    "\n",
    "    melted_df.to_csv(file_name, index=False)\n",
    "    return melted_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stock_name</th>\n",
       "      <th>attention_ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>4.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110485</th>\n",
       "      <td>2023-01-27</td>\n",
       "      <td>WBA</td>\n",
       "      <td>30.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110486</th>\n",
       "      <td>2023-01-28</td>\n",
       "      <td>WBA</td>\n",
       "      <td>23.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110487</th>\n",
       "      <td>2023-01-29</td>\n",
       "      <td>WBA</td>\n",
       "      <td>7.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110488</th>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>WBA</td>\n",
       "      <td>23.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110489</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>WBA</td>\n",
       "      <td>24.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110490 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date stock_name  attention_ticker\n",
       "0       2013-01-01       MSFT              2.60\n",
       "1       2013-01-02       MSFT              5.46\n",
       "2       2013-01-03       MSFT              5.33\n",
       "3       2013-01-04       MSFT              4.29\n",
       "4       2013-01-05       MSFT              2.21\n",
       "...            ...        ...               ...\n",
       "110485  2023-01-27        WBA             30.21\n",
       "110486  2023-01-28        WBA             23.37\n",
       "110487  2023-01-29        WBA              7.98\n",
       "110488  2023-01-30        WBA             23.94\n",
       "110489  2023-01-31        WBA             24.51\n",
       "\n",
       "[110490 rows x 3 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = ['MSFT_trends.csv', 'AAPL_trends.csv', 'Visa_trends.csv', 'JPM_trends.csv', \n",
    "             'UNH_trends.csv',  'WMT_trends.csv', 'JNJ_trends.csv', 'PG_trends.csv',\n",
    "               'HD_trends.csv', 'MRK_trends.csv',  'CVX_trends.csv', 'CRM_trends.csv', \n",
    "               'KO_trends.csv', 'MCD_trends.csv', 'CSCO_trends.csv',  'INTC_trends.csv', \n",
    "               'DIS_trends.csv', 'VZ_trends.csv', 'AMGN_trends.csv', 'IBM_trends.csv',  \n",
    "               'CAT_trends.csv', 'NKE_trends.csv', 'AXP_trends.csv', 'HON_trends.csv', \n",
    "               'BA_trends.csv',  'GS_trends.csv', 'MMM_trends.csv', 'TRV_trends.csv', 'TSLA_trends.csv', 'WBA_trends.csv']\n",
    "\n",
    "ticker_only_df = merge_csv_files(csv_files, \"google_trends_tickers.csv\")\n",
    "ticker_only_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Financial Data from excel to a combined pandas DF for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def xlsx_to_csv(file_names):\n",
    "    folder_name = 'financial_data'\n",
    "    for name in file_names:\n",
    "        file_path = os.path.join(folder_name, f\"{name}.xlsx\")\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Error: File '{file_path}' does not exist.\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_excel(file_path, header=4, skiprows=2)\n",
    "        new_name = os.path.join(folder_name, f'{name}_financial.csv') \n",
    "        df.to_csv(new_name, index=False)\n",
    "    \n",
    "    return 'Done'\n",
    "\n",
    "# Example usage:\n",
    "file_list = ['AAPL', 'MSFT']  # List of filenames without extensions\n",
    "xlsx_to_csv(file_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File 'financial_data/PG.xlsx' does not exist.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlsx_to_csv(djia_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'AAPL_financial.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_tester \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAAPL_financial.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_tester\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1012\u001b[0m     dialect,\n\u001b[1;32m   1013\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1877\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1889\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AAPL_financial.csv'"
     ]
    }
   ],
   "source": [
    "df_tester = pd.read_csv('AAPL_financial.csv')\n",
    "df_tester.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'AAPL.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m test_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAAPL.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAMGN.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m testdf \u001b[38;5;241m=\u001b[39m \u001b[43mcombine_xlsx_to_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAAPL_AMGN.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m, in \u001b[0;36mcombine_xlsx_to_csv\u001b[0;34m(xlsx_files, output_csv)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: File \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Concatenate all dataframes into one\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/excel/_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/excel/_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1557\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/excel/_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AAPL.xlsx'"
     ]
    }
   ],
   "source": [
    "test_list = ['AAPL.xlsx', 'AMGN.xlsx']\n",
    "testdf = combine_xlsx_to_csv(test_list, \"AAPL_AMGN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Price</th>\n",
       "      <th>Circulating Supply</th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>$4,297,535,254.01</td>\n",
       "      <td>$314.25</td>\n",
       "      <td>13,675,575</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>XRP</td>\n",
       "      <td>$755,559,204.14</td>\n",
       "      <td>$0.02439</td>\n",
       "      <td>30,978,075,200</td>\n",
       "      <td>XRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>PayCoin</td>\n",
       "      <td>$95,951,277.32</td>\n",
       "      <td>$7.7846</td>\n",
       "      <td>12,325,857</td>\n",
       "      <td>XPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>Litecoin</td>\n",
       "      <td>$95,086,706.84</td>\n",
       "      <td>$2.6990</td>\n",
       "      <td>35,229,754</td>\n",
       "      <td>LTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>BitShares</td>\n",
       "      <td>$40,794,405.67</td>\n",
       "      <td>$0.01633</td>\n",
       "      <td>2,497,973,773</td>\n",
       "      <td>BTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>MaidSafeCoin</td>\n",
       "      <td>$24,447,792.80</td>\n",
       "      <td>$0.05402</td>\n",
       "      <td>452,552,412</td>\n",
       "      <td>MAID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>Stellar</td>\n",
       "      <td>$19,541,311.09</td>\n",
       "      <td>$0.005493</td>\n",
       "      <td>3,557,202,875</td>\n",
       "      <td>XLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>Dogecoin</td>\n",
       "      <td>$17,778,475.75</td>\n",
       "      <td>$0.0001829</td>\n",
       "      <td>97,225,483,533</td>\n",
       "      <td>DOGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>Nxt</td>\n",
       "      <td>$17,703,597.25</td>\n",
       "      <td>$0.0177</td>\n",
       "      <td>999,997,096</td>\n",
       "      <td>NXT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>Peercoin</td>\n",
       "      <td>$12,831,534.34</td>\n",
       "      <td>$0.5838</td>\n",
       "      <td>21,980,804</td>\n",
       "      <td>PPC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>Counterparty</td>\n",
       "      <td>$10,525,992.65</td>\n",
       "      <td>$3.9772</td>\n",
       "      <td>2,646,592</td>\n",
       "      <td>XCP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>Dash</td>\n",
       "      <td>$9,714,873.81</td>\n",
       "      <td>$1.9433</td>\n",
       "      <td>4,999,096</td>\n",
       "      <td>DASH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>Namecoin</td>\n",
       "      <td>$7,459,610.68</td>\n",
       "      <td>$0.7036</td>\n",
       "      <td>10,601,850</td>\n",
       "      <td>NMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>FuelCoin</td>\n",
       "      <td>$5,031,661.77</td>\n",
       "      <td>$0.05023</td>\n",
       "      <td>100,170,280</td>\n",
       "      <td>FC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>NuShares</td>\n",
       "      <td>$4,135,005.74</td>\n",
       "      <td>$0.006819</td>\n",
       "      <td>606,438,639</td>\n",
       "      <td>NSR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>SuperNET</td>\n",
       "      <td>$3,921,723.97</td>\n",
       "      <td>$4.8057</td>\n",
       "      <td>816,061</td>\n",
       "      <td>UNITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>YbCoin</td>\n",
       "      <td>$3,356,684.09</td>\n",
       "      <td>$1.1189</td>\n",
       "      <td>3,000,000</td>\n",
       "      <td>YBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>Banx</td>\n",
       "      <td>$2,926,530.28</td>\n",
       "      <td>$1.1313</td>\n",
       "      <td>2,586,882</td>\n",
       "      <td>BANX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>Monero</td>\n",
       "      <td>$2,561,248.62</td>\n",
       "      <td>$0.4658</td>\n",
       "      <td>5,499,070</td>\n",
       "      <td>XMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>BlackCoin</td>\n",
       "      <td>$2,305,483.00</td>\n",
       "      <td>$0.03084</td>\n",
       "      <td>74,745,789</td>\n",
       "      <td>BLK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date          Name         Market Cap       Price  \\\n",
       "0   01-01-2015       Bitcoin  $4,297,535,254.01     $314.25   \n",
       "1   01-01-2015           XRP    $755,559,204.14    $0.02439   \n",
       "2   01-01-2015       PayCoin     $95,951,277.32     $7.7846   \n",
       "3   01-01-2015      Litecoin     $95,086,706.84     $2.6990   \n",
       "4   01-01-2015     BitShares     $40,794,405.67    $0.01633   \n",
       "5   01-01-2015  MaidSafeCoin     $24,447,792.80    $0.05402   \n",
       "6   01-01-2015       Stellar     $19,541,311.09   $0.005493   \n",
       "7   01-01-2015      Dogecoin     $17,778,475.75  $0.0001829   \n",
       "8   01-01-2015           Nxt     $17,703,597.25     $0.0177   \n",
       "9   01-01-2015      Peercoin     $12,831,534.34     $0.5838   \n",
       "10  01-01-2015  Counterparty     $10,525,992.65     $3.9772   \n",
       "11  01-01-2015          Dash      $9,714,873.81     $1.9433   \n",
       "12  01-01-2015      Namecoin      $7,459,610.68     $0.7036   \n",
       "13  01-01-2015      FuelCoin      $5,031,661.77    $0.05023   \n",
       "14  01-01-2015      NuShares      $4,135,005.74   $0.006819   \n",
       "15  01-01-2015      SuperNET      $3,921,723.97     $4.8057   \n",
       "16  01-01-2015        YbCoin      $3,356,684.09     $1.1189   \n",
       "17  01-01-2015          Banx      $2,926,530.28     $1.1313   \n",
       "18  01-01-2015        Monero      $2,561,248.62     $0.4658   \n",
       "19  01-01-2015     BlackCoin      $2,305,483.00    $0.03084   \n",
       "\n",
       "   Circulating Supply Symbol  \n",
       "0          13,675,575    BTC  \n",
       "1      30,978,075,200    XRP  \n",
       "2          12,325,857    XPY  \n",
       "3          35,229,754    LTC  \n",
       "4       2,497,973,773    BTS  \n",
       "5         452,552,412   MAID  \n",
       "6       3,557,202,875    XLM  \n",
       "7      97,225,483,533   DOGE  \n",
       "8         999,997,096    NXT  \n",
       "9          21,980,804    PPC  \n",
       "10          2,646,592    XCP  \n",
       "11          4,999,096   DASH  \n",
       "12         10,601,850    NMC  \n",
       "13        100,170,280    FC2  \n",
       "14        606,438,639    NSR  \n",
       "15            816,061  UNITY  \n",
       "16          3,000,000    YBC  \n",
       "17          2,586,882   BANX  \n",
       "18          5,499,070    XMR  \n",
       "19         74,745,789    BLK  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crpyto = pd.read_csv(\"crypto_data/crypto_d15-16.csv\")\n",
    "crpyto.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Price</th>\n",
       "      <th>Circulating Supply</th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14540</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>$15,492,555,878.41</td>\n",
       "      <td>$963.74</td>\n",
       "      <td>16,075,400</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14541</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>$696,993,349.65</td>\n",
       "      <td>$7.9691</td>\n",
       "      <td>87,462,022</td>\n",
       "      <td>ETH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14542</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>XRP</td>\n",
       "      <td>$234,334,889.55</td>\n",
       "      <td>$0.006449</td>\n",
       "      <td>36,337,298,649</td>\n",
       "      <td>XRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14543</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Litecoin</td>\n",
       "      <td>$212,503,030.89</td>\n",
       "      <td>$4.3253</td>\n",
       "      <td>49,130,379</td>\n",
       "      <td>LTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14544</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Monero</td>\n",
       "      <td>$188,311,149.77</td>\n",
       "      <td>$13.78</td>\n",
       "      <td>13,661,732</td>\n",
       "      <td>XMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14545</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Ethereum Classic</td>\n",
       "      <td>$123,523,126.75</td>\n",
       "      <td>$1.4131</td>\n",
       "      <td>87,411,690</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14546</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Dash</td>\n",
       "      <td>$78,344,128.98</td>\n",
       "      <td>$11.21</td>\n",
       "      <td>6,990,724</td>\n",
       "      <td>DASH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14547</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>MaidSafeCoin</td>\n",
       "      <td>$44,950,237.56</td>\n",
       "      <td>$0.09933</td>\n",
       "      <td>452,552,412</td>\n",
       "      <td>MAID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14548</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Augur</td>\n",
       "      <td>$41,523,346.19</td>\n",
       "      <td>$3.7748</td>\n",
       "      <td>11,000,000</td>\n",
       "      <td>REP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14549</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Steem</td>\n",
       "      <td>$38,917,352.19</td>\n",
       "      <td>$0.1695</td>\n",
       "      <td>229,607,487</td>\n",
       "      <td>STEEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14550</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>NEM</td>\n",
       "      <td>$33,084,306.40</td>\n",
       "      <td>$0.003676</td>\n",
       "      <td>8,999,999,999</td>\n",
       "      <td>XEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14551</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Iconomi</td>\n",
       "      <td>$26,761,979.70</td>\n",
       "      <td>$0.3076</td>\n",
       "      <td>87,000,000</td>\n",
       "      <td>ICN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14552</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Factom</td>\n",
       "      <td>$26,390,257.08</td>\n",
       "      <td>$3.0149</td>\n",
       "      <td>8,753,219</td>\n",
       "      <td>FCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14553</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Waves</td>\n",
       "      <td>$25,091,540.81</td>\n",
       "      <td>$0.2509</td>\n",
       "      <td>100,000,000</td>\n",
       "      <td>WAVES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14554</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Dogecoin</td>\n",
       "      <td>$24,029,247.13</td>\n",
       "      <td>$0.0002235</td>\n",
       "      <td>107,529,653,033</td>\n",
       "      <td>DOGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14555</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Stellar</td>\n",
       "      <td>$17,089,497.95</td>\n",
       "      <td>$0.002469</td>\n",
       "      <td>6,921,534,188</td>\n",
       "      <td>XLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14556</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>DigixDAO</td>\n",
       "      <td>$17,071,126.94</td>\n",
       "      <td>$8.5356</td>\n",
       "      <td>2,000,000</td>\n",
       "      <td>DGD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14557</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Zcash</td>\n",
       "      <td>$16,488,137.58</td>\n",
       "      <td>$48.10</td>\n",
       "      <td>342,756</td>\n",
       "      <td>ZEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14558</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Lisk</td>\n",
       "      <td>$14,623,261.47</td>\n",
       "      <td>$0.1444</td>\n",
       "      <td>101,258,695</td>\n",
       "      <td>LSK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14559</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>EDC Blockchain</td>\n",
       "      <td>$13,560,294.00</td>\n",
       "      <td>$0.9955</td>\n",
       "      <td>13,621,634</td>\n",
       "      <td>EDC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date              Name          Market Cap       Price  \\\n",
       "14540  31-12-2016           Bitcoin  $15,492,555,878.41     $963.74   \n",
       "14541  31-12-2016          Ethereum     $696,993,349.65     $7.9691   \n",
       "14542  31-12-2016               XRP     $234,334,889.55   $0.006449   \n",
       "14543  31-12-2016          Litecoin     $212,503,030.89     $4.3253   \n",
       "14544  31-12-2016            Monero     $188,311,149.77      $13.78   \n",
       "14545  31-12-2016  Ethereum Classic     $123,523,126.75     $1.4131   \n",
       "14546  31-12-2016              Dash      $78,344,128.98      $11.21   \n",
       "14547  31-12-2016      MaidSafeCoin      $44,950,237.56    $0.09933   \n",
       "14548  31-12-2016             Augur      $41,523,346.19     $3.7748   \n",
       "14549  31-12-2016             Steem      $38,917,352.19     $0.1695   \n",
       "14550  31-12-2016               NEM      $33,084,306.40   $0.003676   \n",
       "14551  31-12-2016           Iconomi      $26,761,979.70     $0.3076   \n",
       "14552  31-12-2016            Factom      $26,390,257.08     $3.0149   \n",
       "14553  31-12-2016             Waves      $25,091,540.81     $0.2509   \n",
       "14554  31-12-2016          Dogecoin      $24,029,247.13  $0.0002235   \n",
       "14555  31-12-2016           Stellar      $17,089,497.95   $0.002469   \n",
       "14556  31-12-2016          DigixDAO      $17,071,126.94     $8.5356   \n",
       "14557  31-12-2016             Zcash      $16,488,137.58      $48.10   \n",
       "14558  31-12-2016              Lisk      $14,623,261.47     $0.1444   \n",
       "14559  31-12-2016    EDC Blockchain      $13,560,294.00     $0.9955   \n",
       "\n",
       "      Circulating Supply Symbol  \n",
       "14540         16,075,400    BTC  \n",
       "14541         87,462,022    ETH  \n",
       "14542     36,337,298,649    XRP  \n",
       "14543         49,130,379    LTC  \n",
       "14544         13,661,732    XMR  \n",
       "14545         87,411,690    ETC  \n",
       "14546          6,990,724   DASH  \n",
       "14547        452,552,412   MAID  \n",
       "14548         11,000,000    REP  \n",
       "14549        229,607,487  STEEM  \n",
       "14550      8,999,999,999    XEM  \n",
       "14551         87,000,000    ICN  \n",
       "14552          8,753,219    FCT  \n",
       "14553        100,000,000  WAVES  \n",
       "14554    107,529,653,033   DOGE  \n",
       "14555      6,921,534,188    XLM  \n",
       "14556          2,000,000    DGD  \n",
       "14557            342,756    ZEC  \n",
       "14558        101,258,695    LSK  \n",
       "14559         13,621,634    EDC  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crpyto.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File 'google_trends/mez_stock_price.csv' does not exist.\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'google_trends'\n",
    "file_names = []\n",
    "for name in file_names:\n",
    "    file_path = os.path.join(folder_name, f\"{name}.csv\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File '{file_path}' does not exist.\")\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
