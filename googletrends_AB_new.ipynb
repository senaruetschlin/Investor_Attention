{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytrends import dailydata\n",
    "import pandas as pd\n",
    "import time\n",
    "from pytrends.exceptions import ResponseError\n",
    "from pytrends.request import TrendReq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of keywords will be here - can create a loop for this as well\n",
    "#SOURCE: https://stockanalysis.com/list/dow-jones-stocks/\n",
    "#replacing DOW with TSLA and adding AMZN due to it being added to the DJIA on Feb 26, keeping Walgreens regardless\n",
    "djia_tickers = [\n",
    " 'MSFT',\n",
    " 'AAPL', \n",
    " 'Visa', #Visa ticker is just V - google trends might not reflect that correctly so using Visa instead; need to redo - 100 comes before 2013\n",
    " 'JPM',\n",
    " 'UNH', \n",
    " 'WMT',\n",
    " 'JNJ',\n",
    " 'PG', \n",
    " 'HD', \n",
    " 'MRK',\n",
    " 'CVX',\n",
    " 'CRM',\n",
    " 'KO',\n",
    " 'MCD', \n",
    " 'CSCO',\n",
    " 'INTC',\n",
    " 'DIS',\n",
    " 'VZ',\n",
    " 'AMGN', \n",
    " 'IBM',\n",
    " 'CAT',\n",
    " 'NKE',\n",
    " 'AXP', \n",
    " 'HON',\n",
    " 'BA',\n",
    " 'GS',\n",
    " 'MMM', \n",
    " 'TRV',\n",
    " 'TSLA',\n",
    " 'WBA',\n",
    " 'AMZN'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "cryptocurrency_names= [\n",
    "    'Bitcoin', \n",
    "    'Ethereum', \n",
    "    'Binance Coin', \n",
    "    'Solana', \n",
    "    'XRP', \n",
    "    'Cardano', \n",
    "    'Avalanche', \n",
    "    'Dogecoin', \n",
    "    'Chainlink', \n",
    "    'Polkadot', \n",
    "    'Polygon',\n",
    "    'Terra',\n",
    "    'Shiba Inu', \n",
    "    'Bitcoin Cash', \n",
    "    'Litecoin', \n",
    "    'Immutable X', \n",
    "    'Uniswap', \n",
    "    'Filecoin', \n",
    "    'Cosmos',\n",
    "    'Hedera Hashgraph', \n",
    "    'Ethereum Classic', \n",
    "    'Stacks', \n",
    "    'Opium', \n",
    "    'Apt Coin', \n",
    "    'NEAR Protocol', \n",
    "    'Algorand', \n",
    "    'Stellar', \n",
    "    'VeChain',\n",
    "    'Injective Protocol',\n",
    "    'Tia Token'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cryptocurrency_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_trends(inputlist):\n",
    "\n",
    "    for string in inputlist:\n",
    "            # Define the file name with .csv extension\n",
    "        file_name = f\"{string}_trends.csv\"\n",
    "        try:\n",
    "            # Make the request to Google Trends API\n",
    "            data = dailydata.get_daily_data(string, 2013, 1, 2023, 12, geo='US').reset_index()\n",
    "            cols = ['date', f'{string}']\n",
    "            data[cols].to_csv(file_name, index=False) #we only need the two columns \n",
    "                \n",
    "            print(f\"CSV file '{file_name}' has been created.\")   \n",
    "            time.sleep(60)             \n",
    "        except Exception as e:\n",
    "            if \"429\" in str(e):\n",
    "                # Backoff strategy\n",
    "                wait_time = 60\n",
    "                print(f\"Too many requests. Retrying in {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "\n",
    "                \n",
    "            else:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                if not data.empty:\n",
    "                    data.to_csv(file_name, index=False)\n",
    "                break  # Exit the retry loop if it's not a 429 error\n",
    "\n",
    "    return f\"function is complete.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIS:2013-01-01 2013-01-31\n",
      "DIS:2013-02-01 2013-02-28\n",
      "DIS:2013-03-01 2013-03-31\n",
      "DIS:2013-04-01 2013-04-30\n",
      "DIS:2013-05-01 2013-05-31\n",
      "DIS:2013-06-01 2013-06-30\n",
      "DIS:2013-07-01 2013-07-31\n",
      "DIS:2013-08-01 2013-08-31\n",
      "DIS:2013-09-01 2013-09-30\n",
      "DIS:2013-10-01 2013-10-31\n",
      "DIS:2013-11-01 2013-11-30\n",
      "DIS:2013-12-01 2013-12-31\n",
      "DIS:2014-01-01 2014-01-31\n",
      "DIS:2014-02-01 2014-02-28\n",
      "DIS:2014-03-01 2014-03-31\n",
      "DIS:2014-04-01 2014-04-30\n",
      "DIS:2014-05-01 2014-05-31\n",
      "DIS:2014-06-01 2014-06-30\n",
      "DIS:2014-07-01 2014-07-31\n",
      "DIS:2014-08-01 2014-08-31\n",
      "DIS:2014-09-01 2014-09-30\n",
      "DIS:2014-10-01 2014-10-31\n",
      "DIS:2014-11-01 2014-11-30\n",
      "DIS:2014-12-01 2014-12-31\n",
      "DIS:2015-01-01 2015-01-31\n",
      "DIS:2015-02-01 2015-02-28\n",
      "DIS:2015-03-01 2015-03-31\n",
      "DIS:2015-04-01 2015-04-30\n",
      "DIS:2015-05-01 2015-05-31\n",
      "DIS:2015-06-01 2015-06-30\n",
      "DIS:2015-07-01 2015-07-31\n",
      "DIS:2015-08-01 2015-08-31\n",
      "DIS:2015-09-01 2015-09-30\n",
      "DIS:2015-10-01 2015-10-31\n",
      "DIS:2015-11-01 2015-11-30\n",
      "DIS:2015-12-01 2015-12-31\n",
      "DIS:2016-01-01 2016-01-31\n",
      "DIS:2016-02-01 2016-02-29\n",
      "DIS:2016-03-01 2016-03-31\n",
      "DIS:2016-04-01 2016-04-30\n",
      "DIS:2016-05-01 2016-05-31\n",
      "DIS:2016-06-01 2016-06-30\n",
      "DIS:2016-07-01 2016-07-31\n",
      "DIS:2016-08-01 2016-08-31\n",
      "DIS:2016-09-01 2016-09-30\n",
      "DIS:2016-10-01 2016-10-31\n",
      "DIS:2016-11-01 2016-11-30\n",
      "DIS:2016-12-01 2016-12-31\n",
      "DIS:2017-01-01 2017-01-31\n",
      "DIS:2017-02-01 2017-02-28\n",
      "DIS:2017-03-01 2017-03-31\n",
      "DIS:2017-04-01 2017-04-30\n",
      "DIS:2017-05-01 2017-05-31\n",
      "DIS:2017-06-01 2017-06-30\n",
      "DIS:2017-07-01 2017-07-31\n",
      "DIS:2017-08-01 2017-08-31\n",
      "DIS:2017-09-01 2017-09-30\n",
      "DIS:2017-10-01 2017-10-31\n",
      "DIS:2017-11-01 2017-11-30\n",
      "DIS:2017-12-01 2017-12-31\n",
      "DIS:2018-01-01 2018-01-31\n",
      "DIS:2018-02-01 2018-02-28\n",
      "DIS:2018-03-01 2018-03-31\n",
      "DIS:2018-04-01 2018-04-30\n",
      "DIS:2018-05-01 2018-05-31\n",
      "DIS:2018-06-01 2018-06-30\n",
      "DIS:2018-07-01 2018-07-31\n",
      "DIS:2018-08-01 2018-08-31\n",
      "DIS:2018-09-01 2018-09-30\n",
      "DIS:2018-10-01 2018-10-31\n",
      "DIS:2018-11-01 2018-11-30\n",
      "DIS:2018-12-01 2018-12-31\n",
      "DIS:2019-01-01 2019-01-31\n",
      "DIS:2019-02-01 2019-02-28\n",
      "DIS:2019-03-01 2019-03-31\n",
      "DIS:2019-04-01 2019-04-30\n",
      "DIS:2019-05-01 2019-05-31\n",
      "DIS:2019-06-01 2019-06-30\n",
      "DIS:2019-07-01 2019-07-31\n",
      "DIS:2019-08-01 2019-08-31\n",
      "DIS:2019-09-01 2019-09-30\n",
      "DIS:2019-10-01 2019-10-31\n",
      "DIS:2019-11-01 2019-11-30\n",
      "DIS:2019-12-01 2019-12-31\n",
      "DIS:2020-01-01 2020-01-31\n",
      "DIS:2020-02-01 2020-02-29\n",
      "DIS:2020-03-01 2020-03-31\n",
      "DIS:2020-04-01 2020-04-30\n",
      "DIS:2020-05-01 2020-05-31\n",
      "DIS:2020-06-01 2020-06-30\n",
      "DIS:2020-07-01 2020-07-31\n",
      "DIS:2020-08-01 2020-08-31\n",
      "DIS:2020-09-01 2020-09-30\n",
      "DIS:2020-10-01 2020-10-31\n",
      "DIS:2020-11-01 2020-11-30\n",
      "DIS:2020-12-01 2020-12-31\n",
      "DIS:2021-01-01 2021-01-31\n",
      "DIS:2021-02-01 2021-02-28\n",
      "DIS:2021-03-01 2021-03-31\n",
      "DIS:2021-04-01 2021-04-30\n",
      "DIS:2021-05-01 2021-05-31\n",
      "DIS:2021-06-01 2021-06-30\n",
      "DIS:2021-07-01 2021-07-31\n",
      "DIS:2021-08-01 2021-08-31\n",
      "DIS:2021-09-01 2021-09-30\n",
      "DIS:2021-10-01 2021-10-31\n",
      "DIS:2021-11-01 2021-11-30\n",
      "DIS:2021-12-01 2021-12-31\n",
      "DIS:2022-01-01 2022-01-31\n",
      "DIS:2022-02-01 2022-02-28\n",
      "DIS:2022-03-01 2022-03-31\n",
      "DIS:2022-04-01 2022-04-30\n",
      "DIS:2022-05-01 2022-05-31\n",
      "DIS:2022-06-01 2022-06-30\n",
      "DIS:2022-07-01 2022-07-31\n",
      "DIS:2022-08-01 2022-08-31\n",
      "DIS:2022-09-01 2022-09-30\n",
      "DIS:2022-10-01 2022-10-31\n",
      "DIS:2022-11-01 2022-11-30\n",
      "DIS:2022-12-01 2022-12-31\n",
      "DIS:2023-01-01 2023-01-31\n",
      "DIS:2023-02-01 2023-02-28\n",
      "DIS:2023-03-01 2023-03-31\n",
      "DIS:2023-04-01 2023-04-30\n",
      "DIS:2023-05-01 2023-05-31\n",
      "DIS:2023-06-01 2023-06-30\n",
      "DIS:2023-07-01 2023-07-31\n",
      "DIS:2023-08-01 2023-08-31\n",
      "DIS:2023-09-01 2023-09-30\n",
      "DIS:2023-10-01 2023-10-31\n",
      "DIS:2023-11-01 2023-11-30\n",
      "DIS:2023-12-01 2023-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pytrends/dailydata.py:123: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  complete[f'{word}_monthly'].ffill(inplace=True)  # fill NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'DIS.csv' has been created.\n",
      "VZ:2013-01-01 2013-01-31\n",
      "VZ:2013-02-01 2013-02-28\n",
      "VZ:2013-03-01 2013-03-31\n",
      "VZ:2013-04-01 2013-04-30\n",
      "VZ:2013-05-01 2013-05-31\n",
      "VZ:2013-06-01 2013-06-30\n",
      "VZ:2013-07-01 2013-07-31\n",
      "VZ:2013-08-01 2013-08-31\n",
      "VZ:2013-09-01 2013-09-30\n",
      "VZ:2013-10-01 2013-10-31\n",
      "VZ:2013-11-01 2013-11-30\n",
      "VZ:2013-12-01 2013-12-31\n",
      "VZ:2014-01-01 2014-01-31\n",
      "VZ:2014-02-01 2014-02-28\n",
      "VZ:2014-03-01 2014-03-31\n",
      "VZ:2014-04-01 2014-04-30\n",
      "VZ:2014-05-01 2014-05-31\n",
      "VZ:2014-06-01 2014-06-30\n",
      "VZ:2014-07-01 2014-07-31\n",
      "VZ:2014-08-01 2014-08-31\n",
      "VZ:2014-09-01 2014-09-30\n",
      "VZ:2014-10-01 2014-10-31\n",
      "VZ:2014-11-01 2014-11-30\n",
      "VZ:2014-12-01 2014-12-31\n",
      "VZ:2015-01-01 2015-01-31\n",
      "VZ:2015-02-01 2015-02-28\n",
      "VZ:2015-03-01 2015-03-31\n",
      "VZ:2015-04-01 2015-04-30\n",
      "VZ:2015-05-01 2015-05-31\n",
      "VZ:2015-06-01 2015-06-30\n",
      "VZ:2015-07-01 2015-07-31\n",
      "VZ:2015-08-01 2015-08-31\n",
      "VZ:2015-09-01 2015-09-30\n",
      "VZ:2015-10-01 2015-10-31\n",
      "VZ:2015-11-01 2015-11-30\n",
      "VZ:2015-12-01 2015-12-31\n",
      "VZ:2016-01-01 2016-01-31\n",
      "VZ:2016-02-01 2016-02-29\n",
      "VZ:2016-03-01 2016-03-31\n",
      "VZ:2016-04-01 2016-04-30\n",
      "VZ:2016-05-01 2016-05-31\n",
      "VZ:2016-06-01 2016-06-30\n",
      "VZ:2016-07-01 2016-07-31\n",
      "VZ:2016-08-01 2016-08-31\n",
      "VZ:2016-09-01 2016-09-30\n",
      "VZ:2016-10-01 2016-10-31\n",
      "VZ:2016-11-01 2016-11-30\n",
      "VZ:2016-12-01 2016-12-31\n",
      "VZ:2017-01-01 2017-01-31\n",
      "VZ:2017-02-01 2017-02-28\n",
      "VZ:2017-03-01 2017-03-31\n",
      "VZ:2017-04-01 2017-04-30\n",
      "VZ:2017-05-01 2017-05-31\n",
      "VZ:2017-06-01 2017-06-30\n",
      "VZ:2017-07-01 2017-07-31\n",
      "VZ:2017-08-01 2017-08-31\n",
      "VZ:2017-09-01 2017-09-30\n",
      "VZ:2017-10-01 2017-10-31\n",
      "VZ:2017-11-01 2017-11-30\n",
      "VZ:2017-12-01 2017-12-31\n",
      "VZ:2018-01-01 2018-01-31\n",
      "VZ:2018-02-01 2018-02-28\n",
      "VZ:2018-03-01 2018-03-31\n",
      "VZ:2018-04-01 2018-04-30\n",
      "VZ:2018-05-01 2018-05-31\n",
      "VZ:2018-06-01 2018-06-30\n",
      "VZ:2018-07-01 2018-07-31\n",
      "VZ:2018-08-01 2018-08-31\n",
      "VZ:2018-09-01 2018-09-30\n",
      "VZ:2018-10-01 2018-10-31\n",
      "VZ:2018-11-01 2018-11-30\n",
      "VZ:2018-12-01 2018-12-31\n",
      "VZ:2019-01-01 2019-01-31\n",
      "VZ:2019-02-01 2019-02-28\n",
      "VZ:2019-03-01 2019-03-31\n",
      "VZ:2019-04-01 2019-04-30\n",
      "VZ:2019-05-01 2019-05-31\n",
      "VZ:2019-06-01 2019-06-30\n",
      "VZ:2019-07-01 2019-07-31\n",
      "VZ:2019-08-01 2019-08-31\n",
      "VZ:2019-09-01 2019-09-30\n",
      "VZ:2019-10-01 2019-10-31\n",
      "VZ:2019-11-01 2019-11-30\n",
      "VZ:2019-12-01 2019-12-31\n",
      "VZ:2020-01-01 2020-01-31\n",
      "VZ:2020-02-01 2020-02-29\n",
      "VZ:2020-03-01 2020-03-31\n",
      "VZ:2020-04-01 2020-04-30\n",
      "VZ:2020-05-01 2020-05-31\n",
      "VZ:2020-06-01 2020-06-30\n",
      "VZ:2020-07-01 2020-07-31\n",
      "VZ:2020-08-01 2020-08-31\n",
      "VZ:2020-09-01 2020-09-30\n",
      "VZ:2020-10-01 2020-10-31\n",
      "VZ:2020-11-01 2020-11-30\n",
      "VZ:2020-12-01 2020-12-31\n",
      "VZ:2021-01-01 2021-01-31\n",
      "VZ:2021-02-01 2021-02-28\n",
      "VZ:2021-03-01 2021-03-31\n",
      "VZ:2021-04-01 2021-04-30\n",
      "VZ:2021-05-01 2021-05-31\n",
      "VZ:2021-06-01 2021-06-30\n",
      "VZ:2021-07-01 2021-07-31\n",
      "VZ:2021-08-01 2021-08-31\n",
      "VZ:2021-09-01 2021-09-30\n",
      "VZ:2021-10-01 2021-10-31\n",
      "VZ:2021-11-01 2021-11-30\n",
      "VZ:2021-12-01 2021-12-31\n",
      "VZ:2022-01-01 2022-01-31\n",
      "VZ:2022-02-01 2022-02-28\n",
      "VZ:2022-03-01 2022-03-31\n",
      "VZ:2022-04-01 2022-04-30\n",
      "VZ:2022-05-01 2022-05-31\n",
      "VZ:2022-06-01 2022-06-30\n",
      "VZ:2022-07-01 2022-07-31\n",
      "VZ:2022-08-01 2022-08-31\n",
      "VZ:2022-09-01 2022-09-30\n",
      "VZ:2022-10-01 2022-10-31\n",
      "VZ:2022-11-01 2022-11-30\n",
      "VZ:2022-12-01 2022-12-31\n",
      "VZ:2023-01-01 2023-01-31\n",
      "VZ:2023-02-01 2023-02-28\n",
      "VZ:2023-03-01 2023-03-31\n",
      "VZ:2023-04-01 2023-04-30\n",
      "VZ:2023-05-01 2023-05-31\n",
      "VZ:2023-06-01 2023-06-30\n",
      "VZ:2023-07-01 2023-07-31\n",
      "VZ:2023-08-01 2023-08-31\n",
      "VZ:2023-09-01 2023-09-30\n",
      "VZ:2023-10-01 2023-10-31\n",
      "VZ:2023-11-01 2023-11-30\n",
      "VZ:2023-12-01 2023-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pytrends/dailydata.py:123: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  complete[f'{word}_monthly'].ffill(inplace=True)  # fill NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'VZ.csv' has been created.\n",
      "AMGN:2013-01-01 2013-01-31\n",
      "AMGN:2013-02-01 2013-02-28\n",
      "AMGN:2013-03-01 2013-03-31\n",
      "AMGN:2013-04-01 2013-04-30\n",
      "AMGN:2013-05-01 2013-05-31\n",
      "AMGN:2013-06-01 2013-06-30\n",
      "AMGN:2013-07-01 2013-07-31\n",
      "AMGN:2013-08-01 2013-08-31\n",
      "AMGN:2013-09-01 2013-09-30\n",
      "AMGN:2013-10-01 2013-10-31\n",
      "AMGN:2013-11-01 2013-11-30\n",
      "AMGN:2013-12-01 2013-12-31\n",
      "AMGN:2014-01-01 2014-01-31\n",
      "AMGN:2014-02-01 2014-02-28\n",
      "AMGN:2014-03-01 2014-03-31\n",
      "AMGN:2014-04-01 2014-04-30\n",
      "AMGN:2014-05-01 2014-05-31\n",
      "AMGN:2014-06-01 2014-06-30\n",
      "AMGN:2014-07-01 2014-07-31\n",
      "AMGN:2014-08-01 2014-08-31\n",
      "AMGN:2014-09-01 2014-09-30\n",
      "AMGN:2014-10-01 2014-10-31\n",
      "AMGN:2014-11-01 2014-11-30\n",
      "AMGN:2014-12-01 2014-12-31\n",
      "AMGN:2015-01-01 2015-01-31\n",
      "AMGN:2015-02-01 2015-02-28\n",
      "AMGN:2015-03-01 2015-03-31\n",
      "AMGN:2015-04-01 2015-04-30\n",
      "AMGN:2015-05-01 2015-05-31\n",
      "AMGN:2015-06-01 2015-06-30\n",
      "AMGN:2015-07-01 2015-07-31\n",
      "AMGN:2015-08-01 2015-08-31\n",
      "AMGN:2015-09-01 2015-09-30\n",
      "AMGN:2015-10-01 2015-10-31\n",
      "AMGN:2015-11-01 2015-11-30\n",
      "AMGN:2015-12-01 2015-12-31\n",
      "AMGN:2016-01-01 2016-01-31\n",
      "AMGN:2016-02-01 2016-02-29\n",
      "AMGN:2016-03-01 2016-03-31\n",
      "AMGN:2016-04-01 2016-04-30\n",
      "AMGN:2016-05-01 2016-05-31\n",
      "AMGN:2016-06-01 2016-06-30\n",
      "AMGN:2016-07-01 2016-07-31\n",
      "AMGN:2016-08-01 2016-08-31\n",
      "AMGN:2016-09-01 2016-09-30\n",
      "AMGN:2016-10-01 2016-10-31\n",
      "AMGN:2016-11-01 2016-11-30\n",
      "AMGN:2016-12-01 2016-12-31\n",
      "AMGN:2017-01-01 2017-01-31\n",
      "AMGN:2017-02-01 2017-02-28\n",
      "AMGN:2017-03-01 2017-03-31\n",
      "AMGN:2017-04-01 2017-04-30\n",
      "AMGN:2017-05-01 2017-05-31\n",
      "AMGN:2017-06-01 2017-06-30\n",
      "AMGN:2017-07-01 2017-07-31\n",
      "AMGN:2017-08-01 2017-08-31\n",
      "AMGN:2017-09-01 2017-09-30\n",
      "AMGN:2017-10-01 2017-10-31\n",
      "AMGN:2017-11-01 2017-11-30\n",
      "AMGN:2017-12-01 2017-12-31\n",
      "AMGN:2018-01-01 2018-01-31\n",
      "AMGN:2018-02-01 2018-02-28\n",
      "AMGN:2018-03-01 2018-03-31\n",
      "AMGN:2018-04-01 2018-04-30\n",
      "AMGN:2018-05-01 2018-05-31\n",
      "AMGN:2018-06-01 2018-06-30\n",
      "AMGN:2018-07-01 2018-07-31\n",
      "AMGN:2018-08-01 2018-08-31\n",
      "AMGN:2018-09-01 2018-09-30\n",
      "AMGN:2018-10-01 2018-10-31\n",
      "AMGN:2018-11-01 2018-11-30\n",
      "AMGN:2018-12-01 2018-12-31\n",
      "AMGN:2019-01-01 2019-01-31\n",
      "AMGN:2019-02-01 2019-02-28\n",
      "AMGN:2019-03-01 2019-03-31\n",
      "AMGN:2019-04-01 2019-04-30\n",
      "AMGN:2019-05-01 2019-05-31\n",
      "AMGN:2019-06-01 2019-06-30\n",
      "AMGN:2019-07-01 2019-07-31\n",
      "AMGN:2019-08-01 2019-08-31\n",
      "AMGN:2019-09-01 2019-09-30\n",
      "AMGN:2019-10-01 2019-10-31\n",
      "AMGN:2019-11-01 2019-11-30\n",
      "AMGN:2019-12-01 2019-12-31\n",
      "AMGN:2020-01-01 2020-01-31\n",
      "AMGN:2020-02-01 2020-02-29\n",
      "AMGN:2020-03-01 2020-03-31\n",
      "AMGN:2020-04-01 2020-04-30\n",
      "AMGN:2020-05-01 2020-05-31\n",
      "AMGN:2020-06-01 2020-06-30\n",
      "AMGN:2020-07-01 2020-07-31\n",
      "AMGN:2020-08-01 2020-08-31\n",
      "AMGN:2020-09-01 2020-09-30\n",
      "AMGN:2020-10-01 2020-10-31\n",
      "AMGN:2020-11-01 2020-11-30\n",
      "AMGN:2020-12-01 2020-12-31\n",
      "AMGN:2021-01-01 2021-01-31\n",
      "AMGN:2021-02-01 2021-02-28\n",
      "AMGN:2021-03-01 2021-03-31\n",
      "AMGN:2021-04-01 2021-04-30\n",
      "AMGN:2021-05-01 2021-05-31\n",
      "AMGN:2021-06-01 2021-06-30\n",
      "AMGN:2021-07-01 2021-07-31\n",
      "AMGN:2021-08-01 2021-08-31\n",
      "AMGN:2021-09-01 2021-09-30\n",
      "AMGN:2021-10-01 2021-10-31\n",
      "AMGN:2021-11-01 2021-11-30\n",
      "AMGN:2021-12-01 2021-12-31\n",
      "AMGN:2022-01-01 2022-01-31\n",
      "AMGN:2022-02-01 2022-02-28\n",
      "AMGN:2022-03-01 2022-03-31\n",
      "AMGN:2022-04-01 2022-04-30\n",
      "AMGN:2022-05-01 2022-05-31\n",
      "AMGN:2022-06-01 2022-06-30\n",
      "AMGN:2022-07-01 2022-07-31\n",
      "AMGN:2022-08-01 2022-08-31\n",
      "AMGN:2022-09-01 2022-09-30\n",
      "AMGN:2022-10-01 2022-10-31\n",
      "AMGN:2022-11-01 2022-11-30\n",
      "AMGN:2022-12-01 2022-12-31\n",
      "AMGN:2023-01-01 2023-01-31\n",
      "AMGN:2023-02-01 2023-02-28\n",
      "AMGN:2023-03-01 2023-03-31\n",
      "AMGN:2023-04-01 2023-04-30\n",
      "AMGN:2023-05-01 2023-05-31\n",
      "AMGN:2023-06-01 2023-06-30\n",
      "AMGN:2023-07-01 2023-07-31\n",
      "AMGN:2023-08-01 2023-08-31\n",
      "AMGN:2023-09-01 2023-09-30\n",
      "AMGN:2023-10-01 2023-10-31\n",
      "AMGN:2023-11-01 2023-11-30\n",
      "AMGN:2023-12-01 2023-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pytrends/dailydata.py:123: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  complete[f'{word}_monthly'].ffill(inplace=True)  # fill NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'AMGN.csv' has been created.\n",
      "IBM:2013-01-01 2013-01-31\n",
      "IBM:2013-02-01 2013-02-28\n",
      "IBM:2013-03-01 2013-03-31\n",
      "IBM:2013-04-01 2013-04-30\n",
      "IBM:2013-05-01 2013-05-31\n",
      "IBM:2013-06-01 2013-06-30\n",
      "IBM:2013-07-01 2013-07-31\n",
      "IBM:2013-08-01 2013-08-31\n",
      "IBM:2013-09-01 2013-09-30\n",
      "IBM:2013-10-01 2013-10-31\n",
      "IBM:2013-11-01 2013-11-30\n",
      "IBM:2013-12-01 2013-12-31\n",
      "IBM:2014-01-01 2014-01-31\n",
      "IBM:2014-02-01 2014-02-28\n",
      "IBM:2014-03-01 2014-03-31\n",
      "IBM:2014-04-01 2014-04-30\n",
      "IBM:2014-05-01 2014-05-31\n",
      "IBM:2014-06-01 2014-06-30\n",
      "IBM:2014-07-01 2014-07-31\n",
      "IBM:2014-08-01 2014-08-31\n",
      "IBM:2014-09-01 2014-09-30\n",
      "IBM:2014-10-01 2014-10-31\n",
      "IBM:2014-11-01 2014-11-30\n",
      "IBM:2014-12-01 2014-12-31\n",
      "IBM:2015-01-01 2015-01-31\n",
      "IBM:2015-02-01 2015-02-28\n",
      "IBM:2015-03-01 2015-03-31\n",
      "IBM:2015-04-01 2015-04-30\n",
      "IBM:2015-05-01 2015-05-31\n",
      "IBM:2015-06-01 2015-06-30\n",
      "IBM:2015-07-01 2015-07-31\n",
      "IBM:2015-08-01 2015-08-31\n",
      "IBM:2015-09-01 2015-09-30\n",
      "IBM:2015-10-01 2015-10-31\n",
      "IBM:2015-11-01 2015-11-30\n",
      "IBM:2015-12-01 2015-12-31\n",
      "IBM:2016-01-01 2016-01-31\n",
      "IBM:2016-02-01 2016-02-29\n",
      "IBM:2016-03-01 2016-03-31\n",
      "IBM:2016-04-01 2016-04-30\n",
      "IBM:2016-05-01 2016-05-31\n",
      "IBM:2016-06-01 2016-06-30\n",
      "IBM:2016-07-01 2016-07-31\n",
      "IBM:2016-08-01 2016-08-31\n",
      "IBM:2016-09-01 2016-09-30\n",
      "IBM:2016-10-01 2016-10-31\n",
      "IBM:2016-11-01 2016-11-30\n",
      "IBM:2016-12-01 2016-12-31\n",
      "IBM:2017-01-01 2017-01-31\n",
      "IBM:2017-02-01 2017-02-28\n",
      "IBM:2017-03-01 2017-03-31\n",
      "IBM:2017-04-01 2017-04-30\n",
      "IBM:2017-05-01 2017-05-31\n",
      "IBM:2017-06-01 2017-06-30\n",
      "IBM:2017-07-01 2017-07-31\n",
      "IBM:2017-08-01 2017-08-31\n",
      "IBM:2017-09-01 2017-09-30\n",
      "IBM:2017-10-01 2017-10-31\n",
      "IBM:2017-11-01 2017-11-30\n",
      "IBM:2017-12-01 2017-12-31\n",
      "IBM:2018-01-01 2018-01-31\n",
      "IBM:2018-02-01 2018-02-28\n",
      "IBM:2018-03-01 2018-03-31\n",
      "IBM:2018-04-01 2018-04-30\n",
      "IBM:2018-05-01 2018-05-31\n",
      "IBM:2018-06-01 2018-06-30\n",
      "IBM:2018-07-01 2018-07-31\n",
      "IBM:2018-08-01 2018-08-31\n",
      "IBM:2018-09-01 2018-09-30\n",
      "IBM:2018-10-01 2018-10-31\n",
      "IBM:2018-11-01 2018-11-30\n",
      "IBM:2018-12-01 2018-12-31\n",
      "IBM:2019-01-01 2019-01-31\n",
      "IBM:2019-02-01 2019-02-28\n",
      "IBM:2019-03-01 2019-03-31\n",
      "IBM:2019-04-01 2019-04-30\n",
      "IBM:2019-05-01 2019-05-31\n",
      "IBM:2019-06-01 2019-06-30\n",
      "IBM:2019-07-01 2019-07-31\n",
      "IBM:2019-08-01 2019-08-31\n",
      "IBM:2019-09-01 2019-09-30\n",
      "IBM:2019-10-01 2019-10-31\n",
      "IBM:2019-11-01 2019-11-30\n",
      "IBM:2019-12-01 2019-12-31\n",
      "IBM:2020-01-01 2020-01-31\n",
      "IBM:2020-02-01 2020-02-29\n",
      "IBM:2020-03-01 2020-03-31\n",
      "IBM:2020-04-01 2020-04-30\n",
      "IBM:2020-05-01 2020-05-31\n",
      "IBM:2020-06-01 2020-06-30\n",
      "IBM:2020-07-01 2020-07-31\n",
      "IBM:2020-08-01 2020-08-31\n",
      "IBM:2020-09-01 2020-09-30\n",
      "IBM:2020-10-01 2020-10-31\n",
      "IBM:2020-11-01 2020-11-30\n",
      "IBM:2020-12-01 2020-12-31\n",
      "IBM:2021-01-01 2021-01-31\n",
      "IBM:2021-02-01 2021-02-28\n",
      "IBM:2021-03-01 2021-03-31\n",
      "IBM:2021-04-01 2021-04-30\n",
      "IBM:2021-05-01 2021-05-31\n",
      "IBM:2021-06-01 2021-06-30\n",
      "IBM:2021-07-01 2021-07-31\n",
      "IBM:2021-08-01 2021-08-31\n",
      "IBM:2021-09-01 2021-09-30\n",
      "IBM:2021-10-01 2021-10-31\n",
      "IBM:2021-11-01 2021-11-30\n",
      "IBM:2021-12-01 2021-12-31\n",
      "IBM:2022-01-01 2022-01-31\n",
      "IBM:2022-02-01 2022-02-28\n",
      "IBM:2022-03-01 2022-03-31\n",
      "IBM:2022-04-01 2022-04-30\n",
      "IBM:2022-05-01 2022-05-31\n",
      "IBM:2022-06-01 2022-06-30\n",
      "IBM:2022-07-01 2022-07-31\n",
      "IBM:2022-08-01 2022-08-31\n",
      "IBM:2022-09-01 2022-09-30\n",
      "IBM:2022-10-01 2022-10-31\n",
      "IBM:2022-11-01 2022-11-30\n",
      "IBM:2022-12-01 2022-12-31\n",
      "IBM:2023-01-01 2023-01-31\n",
      "IBM:2023-02-01 2023-02-28\n",
      "IBM:2023-03-01 2023-03-31\n",
      "IBM:2023-04-01 2023-04-30\n",
      "IBM:2023-05-01 2023-05-31\n",
      "IBM:2023-06-01 2023-06-30\n",
      "IBM:2023-07-01 2023-07-31\n",
      "IBM:2023-08-01 2023-08-31\n",
      "IBM:2023-09-01 2023-09-30\n",
      "IBM:2023-10-01 2023-10-31\n",
      "IBM:2023-11-01 2023-11-30\n",
      "IBM:2023-12-01 2023-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pytrends/dailydata.py:123: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  complete[f'{word}_monthly'].ffill(inplace=True)  # fill NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'IBM.csv' has been created.\n",
      "TRV:2013-01-01 2013-01-31\n",
      "TRV:2013-02-01 2013-02-28\n",
      "TRV:2013-03-01 2013-03-31\n",
      "TRV:2013-04-01 2013-04-30\n",
      "TRV:2013-05-01 2013-05-31\n",
      "TRV:2013-06-01 2013-06-30\n",
      "TRV:2013-07-01 2013-07-31\n",
      "TRV:2013-08-01 2013-08-31\n",
      "TRV:2013-09-01 2013-09-30\n",
      "TRV:2013-10-01 2013-10-31\n",
      "TRV:2013-11-01 2013-11-30\n",
      "TRV:2013-12-01 2013-12-31\n",
      "TRV:2014-01-01 2014-01-31\n",
      "TRV:2014-02-01 2014-02-28\n",
      "TRV:2014-03-01 2014-03-31\n",
      "TRV:2014-04-01 2014-04-30\n",
      "TRV:2014-05-01 2014-05-31\n",
      "TRV:2014-06-01 2014-06-30\n",
      "TRV:2014-07-01 2014-07-31\n",
      "TRV:2014-08-01 2014-08-31\n",
      "TRV:2014-09-01 2014-09-30\n",
      "TRV:2014-10-01 2014-10-31\n",
      "TRV:2014-11-01 2014-11-30\n",
      "TRV:2014-12-01 2014-12-31\n",
      "TRV:2015-01-01 2015-01-31\n",
      "TRV:2015-02-01 2015-02-28\n",
      "TRV:2015-03-01 2015-03-31\n",
      "TRV:2015-04-01 2015-04-30\n",
      "TRV:2015-05-01 2015-05-31\n",
      "TRV:2015-06-01 2015-06-30\n",
      "TRV:2015-07-01 2015-07-31\n",
      "TRV:2015-08-01 2015-08-31\n",
      "TRV:2015-09-01 2015-09-30\n",
      "TRV:2015-10-01 2015-10-31\n",
      "TRV:2015-11-01 2015-11-30\n",
      "TRV:2015-12-01 2015-12-31\n",
      "TRV:2016-01-01 2016-01-31\n",
      "TRV:2016-02-01 2016-02-29\n",
      "TRV:2016-03-01 2016-03-31\n",
      "TRV:2016-04-01 2016-04-30\n",
      "TRV:2016-05-01 2016-05-31\n",
      "TRV:2016-06-01 2016-06-30\n",
      "TRV:2016-07-01 2016-07-31\n",
      "TRV:2016-08-01 2016-08-31\n",
      "TRV:2016-09-01 2016-09-30\n",
      "TRV:2016-10-01 2016-10-31\n",
      "TRV:2016-11-01 2016-11-30\n",
      "TRV:2016-12-01 2016-12-31\n",
      "TRV:2017-01-01 2017-01-31\n",
      "TRV:2017-02-01 2017-02-28\n",
      "TRV:2017-03-01 2017-03-31\n",
      "TRV:2017-04-01 2017-04-30\n",
      "TRV:2017-05-01 2017-05-31\n",
      "TRV:2017-06-01 2017-06-30\n",
      "TRV:2017-07-01 2017-07-31\n",
      "TRV:2017-08-01 2017-08-31\n",
      "TRV:2017-09-01 2017-09-30\n",
      "TRV:2017-10-01 2017-10-31\n",
      "TRV:2017-11-01 2017-11-30\n",
      "TRV:2017-12-01 2017-12-31\n",
      "TRV:2018-01-01 2018-01-31\n",
      "TRV:2018-02-01 2018-02-28\n",
      "TRV:2018-03-01 2018-03-31\n",
      "TRV:2018-04-01 2018-04-30\n",
      "TRV:2018-05-01 2018-05-31\n",
      "TRV:2018-06-01 2018-06-30\n",
      "TRV:2018-07-01 2018-07-31\n",
      "TRV:2018-08-01 2018-08-31\n",
      "TRV:2018-09-01 2018-09-30\n",
      "TRV:2018-10-01 2018-10-31\n",
      "TRV:2018-11-01 2018-11-30\n",
      "TRV:2018-12-01 2018-12-31\n",
      "TRV:2019-01-01 2019-01-31\n",
      "TRV:2019-02-01 2019-02-28\n",
      "TRV:2019-03-01 2019-03-31\n",
      "TRV:2019-04-01 2019-04-30\n",
      "TRV:2019-05-01 2019-05-31\n",
      "TRV:2019-06-01 2019-06-30\n",
      "TRV:2019-07-01 2019-07-31\n",
      "TRV:2019-08-01 2019-08-31\n",
      "TRV:2019-09-01 2019-09-30\n",
      "TRV:2019-10-01 2019-10-31\n",
      "TRV:2019-11-01 2019-11-30\n",
      "TRV:2019-12-01 2019-12-31\n",
      "TRV:2020-01-01 2020-01-31\n",
      "TRV:2020-02-01 2020-02-29\n",
      "TRV:2020-03-01 2020-03-31\n",
      "TRV:2020-04-01 2020-04-30\n",
      "TRV:2020-05-01 2020-05-31\n",
      "TRV:2020-06-01 2020-06-30\n",
      "TRV:2020-07-01 2020-07-31\n",
      "TRV:2020-08-01 2020-08-31\n",
      "TRV:2020-09-01 2020-09-30\n",
      "TRV:2020-10-01 2020-10-31\n",
      "TRV:2020-11-01 2020-11-30\n",
      "TRV:2020-12-01 2020-12-31\n",
      "TRV:2021-01-01 2021-01-31\n",
      "TRV:2021-02-01 2021-02-28\n",
      "TRV:2021-03-01 2021-03-31\n",
      "TRV:2021-04-01 2021-04-30\n",
      "TRV:2021-05-01 2021-05-31\n",
      "TRV:2021-06-01 2021-06-30\n",
      "TRV:2021-07-01 2021-07-31\n",
      "TRV:2021-08-01 2021-08-31\n",
      "TRV:2021-09-01 2021-09-30\n",
      "TRV:2021-10-01 2021-10-31\n",
      "TRV:2021-11-01 2021-11-30\n",
      "TRV:2021-12-01 2021-12-31\n",
      "TRV:2022-01-01 2022-01-31\n",
      "TRV:2022-02-01 2022-02-28\n",
      "TRV:2022-03-01 2022-03-31\n",
      "TRV:2022-04-01 2022-04-30\n",
      "TRV:2022-05-01 2022-05-31\n",
      "TRV:2022-06-01 2022-06-30\n",
      "TRV:2022-07-01 2022-07-31\n",
      "TRV:2022-08-01 2022-08-31\n",
      "TRV:2022-09-01 2022-09-30\n",
      "TRV:2022-10-01 2022-10-31\n",
      "TRV:2022-11-01 2022-11-30\n",
      "TRV:2022-12-01 2022-12-31\n",
      "TRV:2023-01-01 2023-01-31\n",
      "TRV:2023-02-01 2023-02-28\n",
      "TRV:2023-03-01 2023-03-31\n",
      "TRV:2023-04-01 2023-04-30\n",
      "TRV:2023-05-01 2023-05-31\n",
      "TRV:2023-06-01 2023-06-30\n",
      "TRV:2023-07-01 2023-07-31\n",
      "TRV:2023-08-01 2023-08-31\n",
      "TRV:2023-09-01 2023-09-30\n",
      "TRV:2023-10-01 2023-10-31\n",
      "TRV:2023-11-01 2023-11-30\n",
      "TRV:2023-12-01 2023-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pytrends/dailydata.py:123: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  complete[f'{word}_monthly'].ffill(inplace=True)  # fill NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'TRV.csv' has been created.\n",
      "TSLA:2013-01-01 2013-01-31\n",
      "TSLA:2013-02-01 2013-02-28\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgoogle_trends\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdjia_tickers\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[61], line 8\u001b[0m, in \u001b[0;36mgoogle_trends\u001b[0;34m(inputlist)\u001b[0m\n\u001b[1;32m      5\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstring\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Make the request to Google Trends API\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mdailydata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_daily_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2013\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2023\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      9\u001b[0m     cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstring\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m     data[cols]\u001b[38;5;241m.\u001b[39mto_csv(file_name, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m#we only need the two columns \u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pytrends/dailydata.py:117\u001b[0m, in \u001b[0;36mget_daily_data\u001b[0;34m(word, start_year, start_mon, stop_year, stop_mon, geo, verbose, wait_time)\u001b[0m\n\u001b[1;32m    115\u001b[0m     results[current] \u001b[38;5;241m=\u001b[39m _fetch_data(pytrends, build_payload, timeframe)\n\u001b[1;32m    116\u001b[0m     current \u001b[38;5;241m=\u001b[39m last_date_of_month \u001b[38;5;241m+\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m     sleep(wait_time)  \u001b[38;5;66;03m# don't go too fast or Google will send 429s\u001b[39;00m\n\u001b[1;32m    119\u001b[0m daily \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(results\u001b[38;5;241m.\u001b[39mvalues())\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124misPartial\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    120\u001b[0m complete \u001b[38;5;241m=\u001b[39m daily\u001b[38;5;241m.\u001b[39mjoin(monthly, lsuffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_unscaled\u001b[39m\u001b[38;5;124m'\u001b[39m, rsuffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_monthly\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "google_trends(djia_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_trends(cryptocurrency_names_with_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_list = [\n",
    "    'Ethereum price', \n",
    "    'Tia Token price',\n",
    "   # 'AMZN',\n",
    "  #  'Amazon stock'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethereum price:2013-01-01 2013-01-31\n",
      "Too many requests. Retrying in 60 seconds...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTooManyRequestsError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 8\u001b[0m, in \u001b[0;36mgoogle_trends\u001b[0;34m(inputlist)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Make the request to Google Trends API\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mdailydata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_daily_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2013\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2023\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      9\u001b[0m     cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstring\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pytrends/dailydata.py:115\u001b[0m, in \u001b[0;36mget_daily_data\u001b[0;34m(word, start_year, start_mon, stop_year, stop_mon, geo, verbose, wait_time)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeframe\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m results[current] \u001b[38;5;241m=\u001b[39m \u001b[43m_fetch_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpytrends\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuild_payload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m current \u001b[38;5;241m=\u001b[39m last_date_of_month \u001b[38;5;241m+\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pytrends/dailydata.py:45\u001b[0m, in \u001b[0;36m_fetch_data\u001b[0;34m(pytrends, build_payload, timeframe)\u001b[0m\n\u001b[1;32m     44\u001b[0m         fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpytrends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterest_over_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pytrends/request.py:232\u001b[0m, in \u001b[0;36mTrendReq.interest_over_time\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# make the request and parse the returned json\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m req_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTEREST_OVER_TIME_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_METHOD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrim_chars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mover_time_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(req_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimelineData\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pytrends/request.py:159\u001b[0m, in \u001b[0;36mTrendReq._get_data\u001b[0;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m status_codes\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mtoo_many_requests:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTooManyRequestsError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mResponseError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
      "\u001b[0;31mTooManyRequestsError\u001b[0m: The request failed: Google returned a response with code 429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgoogle_trends\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdated_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 19\u001b[0m, in \u001b[0;36mgoogle_trends\u001b[0;34m(inputlist)\u001b[0m\n\u001b[1;32m     17\u001b[0m     wait_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many requests. Retrying in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwait_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "google_trends(updated_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all the trends into one file to merge with financial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_column_header(input_list):\n",
    "    folder_name = 'google_trends/stock_price'\n",
    "    for name in input_list:\n",
    "        file_name = f\"{name}_price_trends.csv\"\n",
    "        file_path = os.path.join(folder_name, file_name)\n",
    "        \n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Error: File '{file_path}' does not exist.\")\n",
    "            continue\n",
    "\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Rename the second column header\n",
    "        df.rename(columns={df.columns[1]: name}, inplace=True)\n",
    "\n",
    "        # Save the modified CSV file\n",
    "        df.to_csv(file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv_files(input_file, folder_name, column_head, file_name):\n",
    "    dfs = []\n",
    "    for file in input_file:\n",
    "        file_path = os.path.join(folder_name, file)\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Error: File '{file_path}' does not exist.\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        dfs.append(df) #creates a list of the dfs\n",
    "\n",
    "    #merged_df = dfs[0]\n",
    "    merged_df = pd.merge(dfs[0], dfs[1], on='date', how='inner')\n",
    "\n",
    "    for i in range(2, 29):\n",
    "        merged_df = pd.merge(merged_df, dfs[i], on='date', how='inner')\n",
    "        #merged_df.to_csv(\"google_price_trends.csv\")\n",
    "\n",
    "    #for df in dfs[1:]:\n",
    "        #merged_df = pd.merge(merged_df, df, on='date')\n",
    "\n",
    "    melted_df = merged_df.melt(id_vars=['date'], var_name='stock_name', value_name=column_head)\n",
    "\n",
    "    melted_df.to_csv(file_name, index=False)\n",
    "    return melted_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stock_name</th>\n",
       "      <th>ticker_attention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>5.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>4.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date stock_name  ticker_attention\n",
       "0  2013-01-01       MSFT              2.34\n",
       "1  2013-01-02       MSFT              5.85\n",
       "2  2013-01-03       MSFT              5.46\n",
       "3  2013-01-04       MSFT              4.29\n",
       "4  2013-01-05       MSFT              2.60"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_trends = ['MSFT_trends.csv', 'AAPL_trends.csv', 'Visa_trends.csv', 'JPM_trends.csv', \n",
    "             'UNH_trends.csv',  'WMT_trends.csv', 'JNJ_trends.csv', 'PG_trends.csv',\n",
    "               'HD_trends.csv', 'MRK_trends.csv',  'CVX_trends.csv', 'CRM_trends.csv', \n",
    "               'KO_trends.csv', 'MCD_trends.csv', 'CSCO_trends.csv',  'INTC_trends.csv', \n",
    "               'DIS_trends.csv', 'VZ_trends.csv', 'AMGN_trends.csv', 'IBM_trends.csv',  \n",
    "               'CAT_trends.csv', 'NKE_trends.csv', 'AXP_trends.csv', 'HON_trends.csv', \n",
    "               'BA_trends.csv',  'GS_trends.csv', 'MMM_trends.csv', 'TRV_trends.csv', 'TSLA_trends.csv']\n",
    "\n",
    "price_trends = ['MSFT_price_trends.csv', 'AAPL_price_trends.csv', 'Visa_price_trends.csv', 'JPM_price_trends.csv', \n",
    "               'UNH_price_trends.csv', 'WMT_price_trends.csv', 'JNJ_price_trends.csv', 'PG_price_trends.csv', \n",
    "               'HD_price_trends.csv', 'MRK_price_trends.csv', 'CVX_price_trends.csv', 'CRM_price_trends.csv', \n",
    "               'KO_price_trends.csv', 'MCD_price_trends.csv', 'CSCO_price_trends.csv', 'INTC_price_trends.csv', \n",
    "               'DIS_price_trends.csv', 'VZ_price_trends.csv', 'AMGN_price_trends.csv', 'IBM_price_trends.csv', \n",
    "               'CAT_price_trends.csv', 'NKE_price_trends.csv', 'AXP_price_trends.csv', 'HON_price_trends.csv', \n",
    "               'BA_price_trends.csv', 'GS_price_trends.csv', 'MMM_price_trends.csv', 'TRV_price_trends.csv', \n",
    "               'TSLA_price_trends.csv']\n",
    "\n",
    "ticker_only_df = merge_csv_files(ticker_trends, 'google_trends/ticker_only', 'ticker_attention', \"google_ticker_trends.csv\")\n",
    "ticker_only_df.head()\n",
    "#update stock_price_df and ticker_only_df when data added for remaining key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stock_name</th>\n",
       "      <th>name_price_attention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-04</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-05</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date stock_name  name_price_attention\n",
       "0  2014-01-01       MSFT                  1.54\n",
       "1  2014-01-02       MSFT                  3.15\n",
       "2  2014-01-03       MSFT                  1.54\n",
       "3  2014-01-04       MSFT                  1.40\n",
       "4  2014-01-05       MSFT                  2.10"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_price_df = merge_csv_files(csv_files_2, 'google_trends/stock_price', 'name_price_attention', \"google_price_trends.csv\")\n",
    "stock_price_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for any NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                False\n",
       "stock_name          False\n",
       "ticker_attention    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_only_df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                    False\n",
       "stock_name              False\n",
       "name_price_attention    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_price_df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining into one csv file (prep for merge with financial data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>ticker_attention</th>\n",
       "      <th>name_price_attention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>3.38</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-04</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-05</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker  ticker_attention  name_price_attention\n",
       "0  2014-01-01   MSFT              1.56                  1.54\n",
       "1  2014-01-02   MSFT              3.25                  3.15\n",
       "2  2014-01-03   MSFT              3.38                  1.54\n",
       "3  2014-01-04   MSFT              2.08                  1.40\n",
       "4  2014-01-05   MSFT              0.91                  2.10"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#google_trends_df = pd.merge(ticker_only_df,stock_price_df, left_on=['date', 'stock_name'], right_on=['date', 'stock_name'], how='left')\n",
    "#google_trends_df.to_csv('google_trends.csv', index=False)\n",
    "\n",
    "google_trends_df = pd.merge(ticker_only_df, stock_price_df, on=['date', 'stock_name'])\n",
    "google_trends_df = google_trends_df.rename(columns={'stock_name':'ticker'})\n",
    "\n",
    "google_trends_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                    False\n",
       "ticker                  False\n",
       "ticker_attention        False\n",
       "name_price_attention    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_trends_df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_trends_df.to_csv(\"google_trends.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining financial and attention data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>permno</th>\n",
       "      <th>ticker</th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "      <th>return</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>mkt_cap</th>\n",
       "      <th>pct_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>10107</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>27.62</td>\n",
       "      <td>52505405.0</td>\n",
       "      <td>0.034081</td>\n",
       "      <td>27.73</td>\n",
       "      <td>27.1499</td>\n",
       "      <td>27.25</td>\n",
       "      <td>27.43995</td>\n",
       "      <td>231289880.0</td>\n",
       "      <td>3.4081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>10107</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>27.25</td>\n",
       "      <td>48149159.0</td>\n",
       "      <td>-0.013396</td>\n",
       "      <td>27.65</td>\n",
       "      <td>27.1600</td>\n",
       "      <td>27.63</td>\n",
       "      <td>27.40500</td>\n",
       "      <td>228191500.0</td>\n",
       "      <td>-1.3396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>10107</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>26.74</td>\n",
       "      <td>52212339.0</td>\n",
       "      <td>-0.018716</td>\n",
       "      <td>27.34</td>\n",
       "      <td>26.7300</td>\n",
       "      <td>27.27</td>\n",
       "      <td>27.03500</td>\n",
       "      <td>223920760.0</td>\n",
       "      <td>-1.8716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>10107</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>26.69</td>\n",
       "      <td>36663231.0</td>\n",
       "      <td>-0.001870</td>\n",
       "      <td>26.88</td>\n",
       "      <td>26.6400</td>\n",
       "      <td>26.77</td>\n",
       "      <td>26.76000</td>\n",
       "      <td>223502060.0</td>\n",
       "      <td>-0.1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>10107</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>26.55</td>\n",
       "      <td>44316668.0</td>\n",
       "      <td>-0.005245</td>\n",
       "      <td>26.79</td>\n",
       "      <td>26.4600</td>\n",
       "      <td>26.75</td>\n",
       "      <td>26.62500</td>\n",
       "      <td>222329700.0</td>\n",
       "      <td>-0.5245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  permno ticker  price      volume    return   high      low  \\\n",
       "0  2013-01-02   10107   MSFT  27.62  52505405.0  0.034081  27.73  27.1499   \n",
       "1  2013-01-03   10107   MSFT  27.25  48149159.0 -0.013396  27.65  27.1600   \n",
       "2  2013-01-04   10107   MSFT  26.74  52212339.0 -0.018716  27.34  26.7300   \n",
       "3  2013-01-07   10107   MSFT  26.69  36663231.0 -0.001870  26.88  26.6400   \n",
       "4  2013-01-08   10107   MSFT  26.55  44316668.0 -0.005245  26.79  26.4600   \n",
       "\n",
       "    open  avg_price      mkt_cap  pct_return  \n",
       "0  27.25   27.43995  231289880.0      3.4081  \n",
       "1  27.63   27.40500  228191500.0     -1.3396  \n",
       "2  27.27   27.03500  223920760.0     -1.8716  \n",
       "3  26.77   26.76000  223502060.0     -0.1870  \n",
       "4  26.75   26.62500  222329700.0     -0.5245  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_data_df = pd.read_csv(\"djia_daily_data_2013_2023_updated.csv\")\n",
    "financial_data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>permno</th>\n",
       "      <th>ticker</th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "      <th>return</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>mkt_cap</th>\n",
       "      <th>pct_return</th>\n",
       "      <th>ticker_attention</th>\n",
       "      <th>name_price_attention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>10107</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>37.16</td>\n",
       "      <td>30423757.0</td>\n",
       "      <td>-0.006683</td>\n",
       "      <td>37.40</td>\n",
       "      <td>37.10</td>\n",
       "      <td>37.350</td>\n",
       "      <td>37.25</td>\n",
       "      <td>308428000.0</td>\n",
       "      <td>-0.6683</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>10107</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>36.91</td>\n",
       "      <td>30944370.0</td>\n",
       "      <td>-0.006728</td>\n",
       "      <td>37.22</td>\n",
       "      <td>36.60</td>\n",
       "      <td>37.200</td>\n",
       "      <td>36.91</td>\n",
       "      <td>306353000.0</td>\n",
       "      <td>-0.6728</td>\n",
       "      <td>3.38</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>10107</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>36.13</td>\n",
       "      <td>43111355.0</td>\n",
       "      <td>-0.021133</td>\n",
       "      <td>36.89</td>\n",
       "      <td>36.11</td>\n",
       "      <td>36.850</td>\n",
       "      <td>36.50</td>\n",
       "      <td>299879000.0</td>\n",
       "      <td>-2.1133</td>\n",
       "      <td>4.03</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-07</td>\n",
       "      <td>10107</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>36.41</td>\n",
       "      <td>35478667.0</td>\n",
       "      <td>0.007750</td>\n",
       "      <td>36.49</td>\n",
       "      <td>36.21</td>\n",
       "      <td>36.325</td>\n",
       "      <td>36.35</td>\n",
       "      <td>302203000.0</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>10107</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>35.76</td>\n",
       "      <td>59452427.0</td>\n",
       "      <td>-0.017852</td>\n",
       "      <td>36.14</td>\n",
       "      <td>35.58</td>\n",
       "      <td>36.000</td>\n",
       "      <td>35.86</td>\n",
       "      <td>296808000.0</td>\n",
       "      <td>-1.7852</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  permno ticker  price      volume    return   high    low  \\\n",
       "0  2014-01-02   10107   MSFT  37.16  30423757.0 -0.006683  37.40  37.10   \n",
       "1  2014-01-03   10107   MSFT  36.91  30944370.0 -0.006728  37.22  36.60   \n",
       "2  2014-01-06   10107   MSFT  36.13  43111355.0 -0.021133  36.89  36.11   \n",
       "3  2014-01-07   10107   MSFT  36.41  35478667.0  0.007750  36.49  36.21   \n",
       "4  2014-01-08   10107   MSFT  35.76  59452427.0 -0.017852  36.14  35.58   \n",
       "\n",
       "     open  avg_price      mkt_cap  pct_return  ticker_attention  \\\n",
       "0  37.350      37.25  308428000.0     -0.6683              3.25   \n",
       "1  37.200      36.91  306353000.0     -0.6728              3.38   \n",
       "2  36.850      36.50  299879000.0     -2.1133              4.03   \n",
       "3  36.325      36.35  302203000.0      0.7750              4.94   \n",
       "4  36.000      35.86  296808000.0     -1.7852              5.33   \n",
       "\n",
       "   name_price_attention  \n",
       "0                  3.15  \n",
       "1                  1.54  \n",
       "2                  2.24  \n",
       "3                  1.19  \n",
       "4                  1.68  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.merge(financial_data_df, google_trends_df, on=['date', 'ticker'])\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"combined_financial_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing financial data files for cryptocurrencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_names = ['Bitcoin', 'Ethereum', 'Binance Coin', 'Solana', 'XRP', 'Cardano', 'Avalanche', 'Dogecoin', 'Chainlink', 'Polkadot', 'Polygon', 'Terra', 'Shiba Inu', 'Bitcoin Cash', 'Litecoin', 'Immutable X', 'Uniswap', 'Filecoin', 'Cosmos', 'Hedera Hashgraph', 'Ethereum Classic', 'Stacks', 'Opium', 'Apt Coin', 'NEAR Protocol', 'Algorand', 'Stellar', 'VeChain', 'Injective Protocol', 'Tia Token']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File 'financial_data/crypto/Ethereum.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Binance Coin.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Solana.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Avalanche.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Dogecoin.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Polkadot.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Polygon.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Terra.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Shiba Inu.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Immutable X.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Uniswap.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Filecoin.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Cosmos.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Hedera Hashgraph.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Ethereum Classic.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Stacks.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Opium.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Apt Coin.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/NEAR Protocol.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Algorand.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Stellar.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/VeChain.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Injective Protocol.xlsx' does not exist.\n",
      "Error: File 'financial_data/crypto/Tia Token.xlsx' does not exist.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlsx_to_csv(crypto_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File 'financial_data/PG.xlsx' does not exist.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlsx_to_csv(djia_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'AAPL_financial.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_tester \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAAPL_financial.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_tester\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1012\u001b[0m     dialect,\n\u001b[1;32m   1013\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1877\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1889\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AAPL_financial.csv'"
     ]
    }
   ],
   "source": [
    "df_tester = pd.read_csv('AAPL_financial.csv')\n",
    "df_tester.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'AAPL.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m test_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAAPL.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAMGN.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m testdf \u001b[38;5;241m=\u001b[39m \u001b[43mcombine_xlsx_to_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAAPL_AMGN.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m, in \u001b[0;36mcombine_xlsx_to_csv\u001b[0;34m(xlsx_files, output_csv)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: File \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Concatenate all dataframes into one\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/excel/_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/excel/_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1557\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/excel/_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AAPL.xlsx'"
     ]
    }
   ],
   "source": [
    "test_list = ['AAPL.xlsx', 'AMGN.xlsx']\n",
    "testdf = combine_xlsx_to_csv(test_list, \"AAPL_AMGN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Microsoft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-01-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-01-03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-01-04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-01-05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2004-01-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2004-01-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2004-01-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2004-01-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2004-01-10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2004-01-11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2004-01-12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2004-01-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2004-01-14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2004-01-15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2004-01-16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2004-01-17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2004-01-18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2004-01-19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2004-01-20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  Microsoft\n",
       "0   2004-01-01        0.0\n",
       "1   2004-01-02        0.0\n",
       "2   2004-01-03        0.0\n",
       "3   2004-01-04        0.0\n",
       "4   2004-01-05        0.0\n",
       "5   2004-01-06        0.0\n",
       "6   2004-01-07        0.0\n",
       "7   2004-01-08        0.0\n",
       "8   2004-01-09        0.0\n",
       "9   2004-01-10        0.0\n",
       "10  2004-01-11        0.0\n",
       "11  2004-01-12        0.0\n",
       "12  2004-01-13        0.0\n",
       "13  2004-01-14        0.0\n",
       "14  2004-01-15        0.0\n",
       "15  2004-01-16        0.0\n",
       "16  2004-01-17        0.0\n",
       "17  2004-01-18        0.0\n",
       "18  2004-01-19        0.0\n",
       "19  2004-01-20        0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crpyto = pd.read_csv(\"Microsoft.csv\")\n",
    "crpyto.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Price</th>\n",
       "      <th>Circulating Supply</th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14540</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>$15,492,555,878.41</td>\n",
       "      <td>$963.74</td>\n",
       "      <td>16,075,400</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14541</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>$696,993,349.65</td>\n",
       "      <td>$7.9691</td>\n",
       "      <td>87,462,022</td>\n",
       "      <td>ETH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14542</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>XRP</td>\n",
       "      <td>$234,334,889.55</td>\n",
       "      <td>$0.006449</td>\n",
       "      <td>36,337,298,649</td>\n",
       "      <td>XRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14543</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Litecoin</td>\n",
       "      <td>$212,503,030.89</td>\n",
       "      <td>$4.3253</td>\n",
       "      <td>49,130,379</td>\n",
       "      <td>LTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14544</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Monero</td>\n",
       "      <td>$188,311,149.77</td>\n",
       "      <td>$13.78</td>\n",
       "      <td>13,661,732</td>\n",
       "      <td>XMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14545</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Ethereum Classic</td>\n",
       "      <td>$123,523,126.75</td>\n",
       "      <td>$1.4131</td>\n",
       "      <td>87,411,690</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14546</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Dash</td>\n",
       "      <td>$78,344,128.98</td>\n",
       "      <td>$11.21</td>\n",
       "      <td>6,990,724</td>\n",
       "      <td>DASH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14547</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>MaidSafeCoin</td>\n",
       "      <td>$44,950,237.56</td>\n",
       "      <td>$0.09933</td>\n",
       "      <td>452,552,412</td>\n",
       "      <td>MAID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14548</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Augur</td>\n",
       "      <td>$41,523,346.19</td>\n",
       "      <td>$3.7748</td>\n",
       "      <td>11,000,000</td>\n",
       "      <td>REP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14549</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Steem</td>\n",
       "      <td>$38,917,352.19</td>\n",
       "      <td>$0.1695</td>\n",
       "      <td>229,607,487</td>\n",
       "      <td>STEEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14550</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>NEM</td>\n",
       "      <td>$33,084,306.40</td>\n",
       "      <td>$0.003676</td>\n",
       "      <td>8,999,999,999</td>\n",
       "      <td>XEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14551</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Iconomi</td>\n",
       "      <td>$26,761,979.70</td>\n",
       "      <td>$0.3076</td>\n",
       "      <td>87,000,000</td>\n",
       "      <td>ICN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14552</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Factom</td>\n",
       "      <td>$26,390,257.08</td>\n",
       "      <td>$3.0149</td>\n",
       "      <td>8,753,219</td>\n",
       "      <td>FCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14553</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Waves</td>\n",
       "      <td>$25,091,540.81</td>\n",
       "      <td>$0.2509</td>\n",
       "      <td>100,000,000</td>\n",
       "      <td>WAVES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14554</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Dogecoin</td>\n",
       "      <td>$24,029,247.13</td>\n",
       "      <td>$0.0002235</td>\n",
       "      <td>107,529,653,033</td>\n",
       "      <td>DOGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14555</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Stellar</td>\n",
       "      <td>$17,089,497.95</td>\n",
       "      <td>$0.002469</td>\n",
       "      <td>6,921,534,188</td>\n",
       "      <td>XLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14556</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>DigixDAO</td>\n",
       "      <td>$17,071,126.94</td>\n",
       "      <td>$8.5356</td>\n",
       "      <td>2,000,000</td>\n",
       "      <td>DGD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14557</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Zcash</td>\n",
       "      <td>$16,488,137.58</td>\n",
       "      <td>$48.10</td>\n",
       "      <td>342,756</td>\n",
       "      <td>ZEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14558</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>Lisk</td>\n",
       "      <td>$14,623,261.47</td>\n",
       "      <td>$0.1444</td>\n",
       "      <td>101,258,695</td>\n",
       "      <td>LSK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14559</th>\n",
       "      <td>31-12-2016</td>\n",
       "      <td>EDC Blockchain</td>\n",
       "      <td>$13,560,294.00</td>\n",
       "      <td>$0.9955</td>\n",
       "      <td>13,621,634</td>\n",
       "      <td>EDC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date              Name          Market Cap       Price  \\\n",
       "14540  31-12-2016           Bitcoin  $15,492,555,878.41     $963.74   \n",
       "14541  31-12-2016          Ethereum     $696,993,349.65     $7.9691   \n",
       "14542  31-12-2016               XRP     $234,334,889.55   $0.006449   \n",
       "14543  31-12-2016          Litecoin     $212,503,030.89     $4.3253   \n",
       "14544  31-12-2016            Monero     $188,311,149.77      $13.78   \n",
       "14545  31-12-2016  Ethereum Classic     $123,523,126.75     $1.4131   \n",
       "14546  31-12-2016              Dash      $78,344,128.98      $11.21   \n",
       "14547  31-12-2016      MaidSafeCoin      $44,950,237.56    $0.09933   \n",
       "14548  31-12-2016             Augur      $41,523,346.19     $3.7748   \n",
       "14549  31-12-2016             Steem      $38,917,352.19     $0.1695   \n",
       "14550  31-12-2016               NEM      $33,084,306.40   $0.003676   \n",
       "14551  31-12-2016           Iconomi      $26,761,979.70     $0.3076   \n",
       "14552  31-12-2016            Factom      $26,390,257.08     $3.0149   \n",
       "14553  31-12-2016             Waves      $25,091,540.81     $0.2509   \n",
       "14554  31-12-2016          Dogecoin      $24,029,247.13  $0.0002235   \n",
       "14555  31-12-2016           Stellar      $17,089,497.95   $0.002469   \n",
       "14556  31-12-2016          DigixDAO      $17,071,126.94     $8.5356   \n",
       "14557  31-12-2016             Zcash      $16,488,137.58      $48.10   \n",
       "14558  31-12-2016              Lisk      $14,623,261.47     $0.1444   \n",
       "14559  31-12-2016    EDC Blockchain      $13,560,294.00     $0.9955   \n",
       "\n",
       "      Circulating Supply Symbol  \n",
       "14540         16,075,400    BTC  \n",
       "14541         87,462,022    ETH  \n",
       "14542     36,337,298,649    XRP  \n",
       "14543         49,130,379    LTC  \n",
       "14544         13,661,732    XMR  \n",
       "14545         87,411,690    ETC  \n",
       "14546          6,990,724   DASH  \n",
       "14547        452,552,412   MAID  \n",
       "14548         11,000,000    REP  \n",
       "14549        229,607,487  STEEM  \n",
       "14550      8,999,999,999    XEM  \n",
       "14551         87,000,000    ICN  \n",
       "14552          8,753,219    FCT  \n",
       "14553        100,000,000  WAVES  \n",
       "14554    107,529,653,033   DOGE  \n",
       "14555      6,921,534,188    XLM  \n",
       "14556          2,000,000    DGD  \n",
       "14557            342,756    ZEC  \n",
       "14558        101,258,695    LSK  \n",
       "14559         13,621,634    EDC  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crpyto.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File 'google_trends/mez_stock_price.csv' does not exist.\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'google_trends'\n",
    "file_names = []\n",
    "for name in file_names:\n",
    "    file_path = os.path.join(folder_name, f\"{name}.csv\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File '{file_path}' does not exist.\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File 'google_trends/stock_price/AMZN_price_trends.csv' does not exist.\n"
     ]
    }
   ],
   "source": [
    "# Assuming df_list is your list of DataFrames\n",
    "\n",
    "folder_name = 'google_trends/stock_price'\n",
    "file_names = djia_tickers\n",
    "\n",
    "\n",
    "\n",
    "for name in file_names:\n",
    "    file_path = os.path.join(folder_name, f\"{name}_price_trends.csv\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File '{file_path}' does not exist.\")\n",
    "        continue\n",
    "    else:\n",
    "        df = pd.read_csv(file_path)  # Use file_path instead of just the name\n",
    "        df = df.drop(df.columns[1:4], axis=1)\n",
    "        df.to_csv(file_path, index=False)  # Save the modified DataFrame back to the same CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rename_files(input_list):\n",
    "    for string in input_list:\n",
    "        updated_file_path = f\"google_trends/ticker_only/{string}.csv\"\n",
    "        \n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(updated_file_path):\n",
    "            print(f\"File {updated_file_path} does not exist. Skipping to next item.\")\n",
    "            continue\n",
    "        \n",
    "        # Construct new file path\n",
    "        new_file_path = f\"{string}_trends.csv\"\n",
    "        \n",
    "        # Rename the file\n",
    "        os.rename(updated_file_path, new_file_path)\n",
    "        print(f\"Renamed {updated_file_path} to {new_file_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for ticker in djia_tickers:\n",
    "    file_name = f\"{ticker}_trends.csv\"\n",
    "    folder_name = \"google_trends/ticker_only\"\n",
    "    file_path = os.path.join(folder_name, file_name)  # Corrected variable name to file_name\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File '{file_path}' does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>VISA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-01-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-01-03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-01-04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-01-05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  VISA\n",
       "0  2004-01-01   0.0\n",
       "1  2004-01-02   0.0\n",
       "2  2004-01-03   0.0\n",
       "3  2004-01-04   0.0\n",
       "4  2004-01-05   0.0"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"google_trends/stock_price/VISA_price_trends.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df['date'] > '2012-12-31']\n",
    "df_filtered.head()\n",
    "df_filtered.to_csv(\"google_trends/stock_price/VISA_price_trends.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
